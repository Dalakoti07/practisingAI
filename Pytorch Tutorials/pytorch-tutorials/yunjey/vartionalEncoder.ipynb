{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory if not exists\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lonewolf/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/lonewolf/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 34991.5391, KL Div: 2843.4480\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29807.9141, KL Div: 973.3571\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 26545.2480, KL Div: 1200.6675\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 26738.6016, KL Div: 581.5673\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 25813.3027, KL Div: 751.3923\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 24863.9102, KL Div: 687.7689\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 25941.3809, KL Div: 817.6965\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 25080.5742, KL Div: 798.7938\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 23489.7676, KL Div: 1120.5010\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 23756.9219, KL Div: 1261.2566\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 22593.3477, KL Div: 1412.3912\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 20466.6328, KL Div: 1511.1536\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 19810.3203, KL Div: 1774.1831\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19415.9199, KL Div: 1705.3755\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 19688.4531, KL Div: 1749.7915\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 19094.8438, KL Div: 1907.2119\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18844.6836, KL Div: 1776.4561\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 19726.1680, KL Div: 1792.6807\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 17656.1211, KL Div: 1866.2654\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 18427.0430, KL Div: 1876.8619\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 18023.7988, KL Div: 1878.8635\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 17910.3086, KL Div: 1988.7190\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 16306.2891, KL Div: 1952.2859\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 17486.6504, KL Div: 1973.4343\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 17693.1484, KL Div: 2058.2141\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 16756.3672, KL Div: 2028.7421\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 16075.5889, KL Div: 2183.9033\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 16349.5801, KL Div: 2070.2388\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 16136.1621, KL Div: 2193.4434\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15879.8340, KL Div: 2266.4705\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 15882.1777, KL Div: 2138.4292\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 15505.1074, KL Div: 2268.2703\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 15120.4961, KL Div: 2364.2339\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 14914.6543, KL Div: 2347.5146\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 15655.7383, KL Div: 2296.9170\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 15055.9062, KL Div: 2612.6416\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 14213.3809, KL Div: 2510.9006\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14829.7637, KL Div: 2323.7869\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14318.5586, KL Div: 2629.7300\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14131.2676, KL Div: 2492.1880\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 14444.9746, KL Div: 2454.3982\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 14425.6406, KL Div: 2698.9307\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 14794.3877, KL Div: 2502.3987\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 14331.2168, KL Div: 2560.7964\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 14302.7422, KL Div: 2571.0540\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 13974.6660, KL Div: 2596.4651\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 13943.6875, KL Div: 2627.3167\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 14116.7207, KL Div: 2584.0393\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 14281.9014, KL Div: 2672.2554\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 14497.0088, KL Div: 2753.7927\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13513.0000, KL Div: 2730.6147\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 13820.3086, KL Div: 2612.0337\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 12869.8926, KL Div: 2747.9922\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13546.9248, KL Div: 2743.0469\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 13174.9160, KL Div: 2649.7388\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 14285.7383, KL Div: 2775.7129\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 13250.1064, KL Div: 2666.7949\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 13027.1016, KL Div: 2799.3560\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 13681.9160, KL Div: 2866.6150\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 13116.2090, KL Div: 2666.1829\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 13531.9648, KL Div: 2830.9395\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 12573.3066, KL Div: 2692.6675\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 12637.4102, KL Div: 2795.7495\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 12862.1230, KL Div: 2849.2197\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 13453.0215, KL Div: 2729.0833\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12989.5254, KL Div: 2759.8118\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 11715.2363, KL Div: 2714.4399\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12948.3594, KL Div: 2898.5554\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12893.2070, KL Div: 2873.7852\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12476.4990, KL Div: 2819.2485\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12345.3535, KL Div: 2786.9165\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12495.9902, KL Div: 2900.5059\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12566.9023, KL Div: 2886.5996\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 11990.3887, KL Div: 2865.9019\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 12364.8486, KL Div: 2791.8540\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 11913.9844, KL Div: 2943.2407\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12419.3359, KL Div: 2830.9001\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 12691.8096, KL Div: 2965.2505\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12594.1133, KL Div: 2846.8445\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 11954.9629, KL Div: 2880.8459\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12017.3711, KL Div: 2992.3403\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 12282.7988, KL Div: 2872.4485\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 12378.2188, KL Div: 2857.2627\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 12601.4102, KL Div: 2965.4512\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12171.6406, KL Div: 2973.8086\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 12321.4238, KL Div: 3029.3452\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 11996.0498, KL Div: 2886.1055\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 12711.5615, KL Div: 2891.9756\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 11756.9648, KL Div: 2961.0737\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 12723.3047, KL Div: 2957.4958\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 12664.7949, KL Div: 2994.7305\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 11561.4326, KL Div: 2946.0581\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 11430.5059, KL Div: 2922.8010\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 12397.2861, KL Div: 3065.6572\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 11546.8008, KL Div: 2992.8291\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 12465.0430, KL Div: 2947.1250\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 11829.8496, KL Div: 2986.5674\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11995.0762, KL Div: 2972.1243\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 11638.6465, KL Div: 2876.9575\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 12472.0996, KL Div: 3021.9397\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 12038.9229, KL Div: 3003.6355\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 11348.5918, KL Div: 2982.1992\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 11624.2041, KL Div: 2992.8496\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11494.8184, KL Div: 3073.0569\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 12123.3516, KL Div: 2952.1221\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11641.9756, KL Div: 3037.6060\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 11611.1699, KL Div: 3000.0078\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11308.1748, KL Div: 3033.0508\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11426.8125, KL Div: 2963.2085\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 12076.1328, KL Div: 2899.3057\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11440.7461, KL Div: 3047.5137\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 12422.9004, KL Div: 3033.2476\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11664.2021, KL Div: 3007.1814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/15], Step [220/469], Reconst Loss: 11700.6621, KL Div: 3036.6392\n",
      "Epoch[3/15], Step [230/469], Reconst Loss: 11607.0498, KL Div: 2963.3672\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11409.3086, KL Div: 3146.4500\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11474.8779, KL Div: 3033.5789\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 11187.1836, KL Div: 3004.5249\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11989.0498, KL Div: 3050.4292\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11747.5000, KL Div: 3030.7771\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 11646.5078, KL Div: 3204.7668\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11617.2578, KL Div: 3086.5381\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11256.4629, KL Div: 3072.4797\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11495.5156, KL Div: 3047.2241\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11158.7686, KL Div: 3060.0325\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11672.8027, KL Div: 3077.6992\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11379.7012, KL Div: 3045.8469\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11915.9727, KL Div: 3030.9575\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 11551.3213, KL Div: 3103.5698\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 11232.5088, KL Div: 2932.8076\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11284.0352, KL Div: 3162.6167\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 10984.2686, KL Div: 2902.6533\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11468.2266, KL Div: 3254.4531\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 10994.0967, KL Div: 3124.6340\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11420.8232, KL Div: 2988.5398\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11670.3359, KL Div: 3187.4023\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11399.0654, KL Div: 3121.8142\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11433.3711, KL Div: 3129.4565\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 11386.7686, KL Div: 3164.8467\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 11119.5693, KL Div: 3148.5146\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 11046.2188, KL Div: 3070.5022\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 11791.0430, KL Div: 3124.3066\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11693.0742, KL Div: 3070.0537\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11400.6729, KL Div: 3266.5059\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11343.6445, KL Div: 3082.2261\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11389.6006, KL Div: 3073.1079\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11074.6660, KL Div: 3077.6199\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 11444.2363, KL Div: 3204.2598\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 11250.6572, KL Div: 3131.8472\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 11149.3467, KL Div: 3090.1650\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11124.9990, KL Div: 3057.7783\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 11625.9873, KL Div: 3228.6836\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 11437.1367, KL Div: 3132.1841\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 11309.1289, KL Div: 3080.1326\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 11296.6758, KL Div: 3075.5864\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 10745.0762, KL Div: 3076.0786\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 10978.9746, KL Div: 3175.1963\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 11200.9648, KL Div: 3144.5359\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 10822.6035, KL Div: 3088.0293\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 11065.8242, KL Div: 3215.3333\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 10907.2695, KL Div: 3147.2104\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 11664.7793, KL Div: 3205.3735\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 11285.0371, KL Div: 3183.0200\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 11113.7285, KL Div: 3124.3223\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 10623.9541, KL Div: 3122.0605\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 10851.0938, KL Div: 3205.0972\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 10713.1328, KL Div: 3051.4014\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 11228.4023, KL Div: 3106.7881\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 11300.2295, KL Div: 3280.2690\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 11249.1035, KL Div: 3045.9670\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 10703.1787, KL Div: 3203.3337\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 11158.5479, KL Div: 3119.2036\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 11560.4756, KL Div: 3316.9492\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 10640.8447, KL Div: 2976.7253\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 10765.5996, KL Div: 3242.1951\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 10811.7900, KL Div: 3075.4807\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11111.1094, KL Div: 3172.0232\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 11734.5391, KL Div: 3249.8262\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 11138.2900, KL Div: 3077.0054\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 11188.7842, KL Div: 3263.2515\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 10765.8906, KL Div: 3187.9175\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 11367.3916, KL Div: 3184.8496\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 11399.0410, KL Div: 3305.1987\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 11373.0625, KL Div: 3183.6377\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 11127.0117, KL Div: 3170.7039\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 11640.3730, KL Div: 3144.0227\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 10650.8604, KL Div: 3003.2561\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 10481.3584, KL Div: 3296.1921\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 11332.1787, KL Div: 3182.9128\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 11087.9893, KL Div: 3197.7388\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 11274.5781, KL Div: 3276.9028\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 11824.3574, KL Div: 3013.1970\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 10907.2842, KL Div: 3217.9026\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 10431.9961, KL Div: 3165.4968\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 10731.1719, KL Div: 3111.6152\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 11015.9004, KL Div: 3236.2979\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 11637.4707, KL Div: 3163.9038\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 11164.9277, KL Div: 3223.6768\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 10942.8945, KL Div: 3109.5811\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 11071.3457, KL Div: 3215.1831\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 10820.3721, KL Div: 3123.9255\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 11182.2637, KL Div: 3247.0054\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 11342.9355, KL Div: 3157.2627\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10750.7910, KL Div: 3196.5205\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 11051.3379, KL Div: 3100.5566\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 10318.7119, KL Div: 3127.9006\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 10845.2715, KL Div: 3131.1663\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 10952.0273, KL Div: 3187.4473\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 11232.5762, KL Div: 3256.1160\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 11543.0273, KL Div: 3179.1504\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 11264.3652, KL Div: 3155.9287\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 10421.7656, KL Div: 3101.6436\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 11137.1260, KL Div: 3194.0449\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 10843.0791, KL Div: 3082.9978\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 10666.3828, KL Div: 3085.6597\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 10756.7568, KL Div: 3172.7754\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 10753.5254, KL Div: 3208.9038\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 11119.8926, KL Div: 3174.2148\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10596.8174, KL Div: 3211.8433\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 11308.4023, KL Div: 3143.9214\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 11612.5918, KL Div: 3251.8523\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 10647.7227, KL Div: 3281.9097\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 10474.2354, KL Div: 3096.5381\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10474.5000, KL Div: 3278.0195\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 10694.8984, KL Div: 3019.5947\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 10685.4336, KL Div: 3234.0347\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 10947.7471, KL Div: 3194.4102\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 10445.8828, KL Div: 3145.7793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/15], Step [450/469], Reconst Loss: 10484.1807, KL Div: 3114.2612\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 10339.2959, KL Div: 3127.2749\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 11047.0205, KL Div: 3228.0884\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10319.2314, KL Div: 3122.6074\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10570.1494, KL Div: 3113.0796\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 11039.0645, KL Div: 3133.2402\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 11135.5137, KL Div: 3271.9707\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 10914.9111, KL Div: 3215.7097\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 11176.8496, KL Div: 3185.8130\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 11107.1494, KL Div: 3204.2788\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 10778.5537, KL Div: 3228.1541\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10815.6396, KL Div: 3082.5100\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 10977.6348, KL Div: 3303.9810\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 10905.3643, KL Div: 3244.8064\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 10590.3320, KL Div: 3064.3677\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10740.8555, KL Div: 3337.9612\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 10772.4082, KL Div: 3171.1636\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 10740.8789, KL Div: 3188.1077\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 11060.5439, KL Div: 3075.6289\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10860.6904, KL Div: 3209.5010\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 10600.2021, KL Div: 3211.7012\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10791.6426, KL Div: 3280.7537\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 10762.9785, KL Div: 3208.0115\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10603.6377, KL Div: 3105.9224\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 10584.5684, KL Div: 3057.9600\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10753.2607, KL Div: 3284.1963\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 10961.8945, KL Div: 3205.5728\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10745.2676, KL Div: 3150.9812\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10660.1758, KL Div: 3167.2080\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 10586.7539, KL Div: 3214.9497\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 10865.6738, KL Div: 3230.3457\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10853.8906, KL Div: 3194.6221\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 10612.6172, KL Div: 3178.2236\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 10588.5156, KL Div: 3129.9036\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 10332.4883, KL Div: 3097.9224\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10765.9590, KL Div: 3237.0950\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 10388.0508, KL Div: 3203.6013\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10611.8945, KL Div: 3253.3384\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 10476.9805, KL Div: 3180.8223\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10653.3408, KL Div: 3181.1187\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10956.6562, KL Div: 3271.0122\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10684.8711, KL Div: 3209.5596\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 10501.7207, KL Div: 3195.7075\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10487.9912, KL Div: 3200.1384\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10927.1152, KL Div: 3203.7930\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10835.6934, KL Div: 3175.3376\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10717.6738, KL Div: 3217.2642\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 10693.5547, KL Div: 3220.3188\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10604.0908, KL Div: 3242.1499\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10626.2559, KL Div: 3217.6523\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 10299.0996, KL Div: 3219.4697\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10305.2441, KL Div: 3149.2095\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 11032.6611, KL Div: 3309.5542\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10429.7324, KL Div: 3230.0312\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10691.6104, KL Div: 3139.2856\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10457.4463, KL Div: 3340.8643\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10626.3896, KL Div: 3115.9736\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10717.5820, KL Div: 3199.8086\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 10902.6152, KL Div: 3227.9272\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10842.2109, KL Div: 3184.5439\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10728.4551, KL Div: 3279.0820\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10877.9199, KL Div: 3161.1685\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10962.7559, KL Div: 3191.1548\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10789.8496, KL Div: 3272.3882\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10618.6045, KL Div: 3215.8503\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10308.3594, KL Div: 3141.8821\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10723.5986, KL Div: 3250.6328\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10493.4795, KL Div: 3135.7815\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10747.1992, KL Div: 3277.1143\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10343.2197, KL Div: 3160.7424\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10797.7734, KL Div: 3251.2773\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10268.6406, KL Div: 3153.7944\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10508.4131, KL Div: 3199.9521\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 11073.9453, KL Div: 3264.1482\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10340.0801, KL Div: 3307.8167\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10410.0479, KL Div: 3179.1360\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 10168.8145, KL Div: 3121.0698\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10502.2568, KL Div: 3219.2957\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10052.0693, KL Div: 3149.7820\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 10658.8154, KL Div: 3220.6782\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10173.4707, KL Div: 3269.0469\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10358.0801, KL Div: 3069.6028\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10457.5547, KL Div: 3225.4512\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10739.4004, KL Div: 3163.8845\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10713.5244, KL Div: 3208.6304\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 10048.7109, KL Div: 3164.5796\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10572.6387, KL Div: 3200.1206\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10913.8389, KL Div: 3237.1716\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10650.5820, KL Div: 3276.0083\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10172.5332, KL Div: 3023.2070\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10783.5117, KL Div: 3274.1733\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10267.4180, KL Div: 3290.9497\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10289.5293, KL Div: 3187.0513\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10420.1836, KL Div: 3195.6482\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10528.8555, KL Div: 3189.9846\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10376.3184, KL Div: 3221.0249\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10485.1982, KL Div: 3208.5791\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10378.2559, KL Div: 3247.7969\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10877.6406, KL Div: 3242.9639\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10507.0029, KL Div: 3102.4709\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10775.6523, KL Div: 3339.0811\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10241.3398, KL Div: 3168.1365\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 9904.3779, KL Div: 3199.1436\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10307.5332, KL Div: 3237.9746\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10222.9736, KL Div: 3114.1367\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10660.5000, KL Div: 3250.7957\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10748.8418, KL Div: 3244.3594\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10660.0059, KL Div: 3241.1548\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 10508.5410, KL Div: 3204.5076\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10251.6523, KL Div: 3124.6819\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10341.9795, KL Div: 3272.0447\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 9902.2178, KL Div: 3144.1384\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10228.5615, KL Div: 3117.0686\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10456.2461, KL Div: 3396.4456\n",
      "Epoch[8/15], Step [210/469], Reconst Loss: 10458.3936, KL Div: 3148.7761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/15], Step [220/469], Reconst Loss: 10122.5820, KL Div: 3241.7998\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10303.4980, KL Div: 3159.5046\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10790.2549, KL Div: 3191.4248\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10921.6631, KL Div: 3274.9714\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10137.8145, KL Div: 3261.5862\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10782.9209, KL Div: 3296.4204\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10126.2852, KL Div: 3223.1914\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10455.3643, KL Div: 3170.4868\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10898.7881, KL Div: 3312.6621\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10866.1719, KL Div: 3226.1077\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10617.4502, KL Div: 3329.8540\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10496.7822, KL Div: 3263.2429\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10612.5107, KL Div: 3198.1318\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 10066.7021, KL Div: 3242.7891\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10533.6465, KL Div: 3270.9023\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10448.1270, KL Div: 3210.5000\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10637.3740, KL Div: 3326.6145\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10258.9365, KL Div: 3088.8997\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10480.7461, KL Div: 3154.6353\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 11065.7656, KL Div: 3325.9639\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10928.6865, KL Div: 3194.9722\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10351.9863, KL Div: 3277.7644\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10430.7783, KL Div: 3156.1965\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 11114.6309, KL Div: 3307.5581\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10635.9580, KL Div: 3251.1467\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10584.1504, KL Div: 3246.1121\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10322.8564, KL Div: 3200.1577\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10347.9609, KL Div: 3233.9470\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10438.1328, KL Div: 3249.5601\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10461.1016, KL Div: 3332.3662\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10310.4395, KL Div: 3345.8032\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10728.9814, KL Div: 3238.0139\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10536.0059, KL Div: 3182.9226\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10614.4736, KL Div: 3341.3760\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10133.8721, KL Div: 3032.5444\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10550.8398, KL Div: 3254.1826\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10052.8770, KL Div: 3187.6055\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 11220.0684, KL Div: 3310.4702\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10394.6543, KL Div: 3237.7903\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 10147.9238, KL Div: 3203.3394\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10300.2520, KL Div: 3271.0098\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10514.3857, KL Div: 3235.0452\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10259.4062, KL Div: 3208.3789\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10130.1758, KL Div: 3293.8813\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10528.0547, KL Div: 3198.7017\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10093.3564, KL Div: 3102.3550\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10899.9961, KL Div: 3311.9307\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10517.7012, KL Div: 3243.8513\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10206.7852, KL Div: 3292.7803\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10445.7891, KL Div: 3253.1289\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10508.1885, KL Div: 3158.6912\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 10515.4004, KL Div: 3250.1428\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10280.3857, KL Div: 3238.4658\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10429.7568, KL Div: 3209.5991\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10231.5293, KL Div: 3207.3350\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10386.1602, KL Div: 3283.7434\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10757.7559, KL Div: 3117.8225\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10495.7656, KL Div: 3301.8965\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10299.8125, KL Div: 3247.5454\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10062.9561, KL Div: 3365.3325\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10831.2832, KL Div: 3130.9097\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10612.3496, KL Div: 3293.1755\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 10230.8252, KL Div: 3193.0259\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 11090.1514, KL Div: 3336.4705\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10073.0303, KL Div: 3133.5845\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 9914.3115, KL Div: 3189.8457\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10415.9062, KL Div: 3355.4468\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10322.6641, KL Div: 3166.2878\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 10439.9189, KL Div: 3282.5432\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10319.0986, KL Div: 3170.1982\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10822.3486, KL Div: 3348.4502\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10369.3105, KL Div: 3251.8596\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10547.4785, KL Div: 3292.7314\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10601.0176, KL Div: 3255.6558\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 10716.1914, KL Div: 3244.0112\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10127.5000, KL Div: 3181.9888\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10822.8672, KL Div: 3287.9248\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 10382.7109, KL Div: 3205.0117\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 10570.3262, KL Div: 3339.9429\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10356.5615, KL Div: 3314.6602\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10020.6514, KL Div: 3191.0237\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10633.6875, KL Div: 3170.6316\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 10675.0723, KL Div: 3258.7578\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 9990.6631, KL Div: 3180.8704\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 9910.0928, KL Div: 3182.4036\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 10608.5049, KL Div: 3211.9995\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 9866.4004, KL Div: 3190.3433\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 9798.7480, KL Div: 3178.0920\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10394.6875, KL Div: 3246.5044\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10285.5879, KL Div: 3264.5361\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10535.3691, KL Div: 3233.2732\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10464.5176, KL Div: 3232.4932\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10316.3770, KL Div: 3279.5527\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10357.4238, KL Div: 3325.8083\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10406.6777, KL Div: 3220.4912\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 9560.0938, KL Div: 3302.0989\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10067.0713, KL Div: 3155.4646\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 10418.8701, KL Div: 3172.3210\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10368.7822, KL Div: 3262.3713\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10725.2012, KL Div: 3279.1970\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10488.9922, KL Div: 3292.8677\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 10360.6621, KL Div: 3253.8379\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10350.5342, KL Div: 3208.6262\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10650.5723, KL Div: 3371.2273\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10099.6172, KL Div: 3216.7212\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 9841.2529, KL Div: 3131.6133\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10366.0869, KL Div: 3323.5015\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 9906.8301, KL Div: 3124.5811\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10345.7939, KL Div: 3243.3716\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 10525.1221, KL Div: 3239.8896\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10333.1104, KL Div: 3299.6572\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 10308.6543, KL Div: 3220.4355\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10165.0312, KL Div: 3188.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/15], Step [430/469], Reconst Loss: 9928.5723, KL Div: 3269.9419\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 10598.8691, KL Div: 3218.8525\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10895.0254, KL Div: 3381.2458\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10846.8242, KL Div: 3215.2686\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10348.5420, KL Div: 3223.1887\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10445.0859, KL Div: 3301.6973\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 10353.0098, KL Div: 3119.5469\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10275.1348, KL Div: 3173.6807\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10250.1055, KL Div: 3250.5698\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10215.8291, KL Div: 3189.8086\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10269.6650, KL Div: 3242.7698\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 10584.1895, KL Div: 3273.4136\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10503.8857, KL Div: 3299.7249\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10533.7646, KL Div: 3261.0354\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 10217.6592, KL Div: 3218.1653\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 9973.9961, KL Div: 3221.6460\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10389.7148, KL Div: 3084.1440\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 10353.4639, KL Div: 3322.2124\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10123.5312, KL Div: 3140.3638\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 10571.6816, KL Div: 3281.7832\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10147.7266, KL Div: 3290.8682\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10472.2324, KL Div: 3344.2559\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 10397.2637, KL Div: 3136.1946\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 9766.8662, KL Div: 3218.8457\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10207.4746, KL Div: 3345.4426\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10223.0078, KL Div: 3237.0901\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 11172.2598, KL Div: 3383.0952\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10535.3281, KL Div: 3307.0767\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10432.1436, KL Div: 3144.5361\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 10121.2188, KL Div: 3353.0776\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10426.5391, KL Div: 3324.5781\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10565.7520, KL Div: 3214.3977\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10602.2656, KL Div: 3359.6870\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 9999.9473, KL Div: 3324.5383\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10459.8301, KL Div: 3200.9436\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 10518.7598, KL Div: 3183.1035\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 10470.6602, KL Div: 3337.1978\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 10044.8887, KL Div: 3209.7207\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 10008.1875, KL Div: 3212.4180\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 9431.6768, KL Div: 3228.8691\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10541.0352, KL Div: 3199.7324\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 10747.8857, KL Div: 3225.6323\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10635.0234, KL Div: 3186.5798\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10218.7070, KL Div: 3155.4653\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10235.3711, KL Div: 3268.7241\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10556.0684, KL Div: 3210.4946\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10011.7939, KL Div: 3118.9619\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 10673.9336, KL Div: 3300.3979\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 10055.1172, KL Div: 3161.6206\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10102.0137, KL Div: 3243.9629\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 10721.4785, KL Div: 3250.2720\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10646.5059, KL Div: 3303.5259\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10565.7715, KL Div: 3234.6079\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10264.6826, KL Div: 3304.5513\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 10345.8477, KL Div: 3271.6758\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 9845.9814, KL Div: 3200.6348\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10302.6592, KL Div: 3270.5425\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10461.4375, KL Div: 3242.4648\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 10266.8594, KL Div: 3356.5312\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10242.7305, KL Div: 3280.6729\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 9877.7930, KL Div: 3143.2563\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10308.1182, KL Div: 3292.8657\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 10259.1299, KL Div: 3271.7827\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 10339.7637, KL Div: 3273.7031\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 11135.6074, KL Div: 3401.6143\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 10051.5869, KL Div: 3198.7349\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10187.5312, KL Div: 3202.2393\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10100.4883, KL Div: 3229.1838\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10370.5957, KL Div: 3165.6958\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10691.8662, KL Div: 3272.3745\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 10545.2568, KL Div: 3340.3247\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 10387.9922, KL Div: 3244.8960\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10288.4180, KL Div: 3299.8101\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 10350.2012, KL Div: 3240.7349\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 10139.6426, KL Div: 3218.3901\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10139.8525, KL Div: 3226.1670\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10278.4932, KL Div: 3141.5054\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10476.7969, KL Div: 3297.4934\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 9832.2686, KL Div: 3169.2798\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10234.1387, KL Div: 3335.8899\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 10228.6553, KL Div: 3272.4658\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 10293.1162, KL Div: 3138.0823\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10684.3809, KL Div: 3304.9805\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10228.2441, KL Div: 3237.0942\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 10122.1689, KL Div: 3227.0825\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 10011.4131, KL Div: 3274.7095\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 10626.9043, KL Div: 3210.7180\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10304.2617, KL Div: 3277.1841\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 10144.1104, KL Div: 3222.0371\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10694.2881, KL Div: 3306.3350\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10430.3350, KL Div: 3242.3201\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10336.2012, KL Div: 3203.8962\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 10187.1953, KL Div: 3234.5078\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10266.7168, KL Div: 3239.1243\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10399.8184, KL Div: 3136.7681\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 9991.8564, KL Div: 3176.4873\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 9968.1826, KL Div: 3178.4236\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 10506.2832, KL Div: 3322.6880\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10166.2949, KL Div: 3202.0874\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 10119.5020, KL Div: 3317.9170\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 10190.1689, KL Div: 3296.2534\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 9924.1582, KL Div: 3255.3213\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 10554.8574, KL Div: 3430.1626\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10653.1602, KL Div: 3295.1658\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10338.3496, KL Div: 3316.3840\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10517.8486, KL Div: 3113.4219\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10313.4160, KL Div: 3230.8503\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10131.4727, KL Div: 3303.3145\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 9996.5654, KL Div: 3119.1655\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 10722.0938, KL Div: 3253.0488\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 10314.6641, KL Div: 3355.3413\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 9956.2129, KL Div: 3208.1096\n",
      "Epoch[13/15], Step [170/469], Reconst Loss: 10531.8965, KL Div: 3150.6106\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10438.3828, KL Div: 3281.5962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/15], Step [190/469], Reconst Loss: 10265.4980, KL Div: 3310.5820\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10384.3252, KL Div: 3334.6938\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10032.3867, KL Div: 3248.2815\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 9954.8984, KL Div: 3203.5073\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10454.3906, KL Div: 3413.2659\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 10353.9238, KL Div: 3304.2456\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10054.6709, KL Div: 3200.4141\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10474.6572, KL Div: 3265.6951\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10365.7607, KL Div: 3293.8564\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10447.0518, KL Div: 3205.6377\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10296.3379, KL Div: 3268.6201\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 10201.3408, KL Div: 3310.9790\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 9929.4502, KL Div: 3173.7883\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10134.0508, KL Div: 3274.1855\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10403.2090, KL Div: 3194.8608\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10492.9395, KL Div: 3329.6279\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10137.6299, KL Div: 3222.6177\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10272.0830, KL Div: 3297.5615\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10848.3311, KL Div: 3314.5432\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10028.3145, KL Div: 3300.7056\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10267.3965, KL Div: 3167.8850\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10001.8877, KL Div: 3100.1428\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 10539.9229, KL Div: 3327.2607\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 10231.3359, KL Div: 3234.6890\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10243.4102, KL Div: 3307.9722\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10465.3164, KL Div: 3294.7930\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 10341.0098, KL Div: 3239.6436\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 9734.3838, KL Div: 3128.5198\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 10038.5977, KL Div: 3265.8867\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 9864.2744, KL Div: 3253.7493\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10076.1943, KL Div: 3203.2798\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10479.4258, KL Div: 3339.1304\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 9569.7998, KL Div: 3180.4326\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 10364.3486, KL Div: 3206.7671\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 10547.9971, KL Div: 3317.8987\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10608.9316, KL Div: 3368.1978\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10223.1777, KL Div: 3254.9082\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 9945.4404, KL Div: 3273.8511\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10412.4121, KL Div: 3298.3872\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10416.5557, KL Div: 3286.7207\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 10369.1797, KL Div: 3377.6328\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 10426.3906, KL Div: 3249.6665\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 9701.5762, KL Div: 3228.1782\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 9978.3691, KL Div: 3161.5093\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 9962.8057, KL Div: 3175.2959\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 10311.6523, KL Div: 3225.5195\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 10397.5381, KL Div: 3240.8264\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10140.5918, KL Div: 3290.3757\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 10559.5176, KL Div: 3271.5449\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10154.0215, KL Div: 3207.6162\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 10255.4053, KL Div: 3352.5459\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10038.0205, KL Div: 3250.9504\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 10203.5352, KL Div: 3265.9397\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 10024.7285, KL Div: 3271.0586\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10494.0215, KL Div: 3343.8210\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 10125.3379, KL Div: 3208.5510\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 9839.7520, KL Div: 3097.8901\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 10175.9902, KL Div: 3324.7749\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 10391.6348, KL Div: 3345.0669\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 10413.3662, KL Div: 3289.8779\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 9743.8418, KL Div: 3180.5933\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 10305.8906, KL Div: 3265.8237\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 10052.4277, KL Div: 3254.7139\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 10267.2236, KL Div: 3243.9868\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10695.4668, KL Div: 3249.1775\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10447.5723, KL Div: 3218.8794\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 10031.1104, KL Div: 3243.0789\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10285.9863, KL Div: 3147.5891\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 10234.7646, KL Div: 3269.8826\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10652.1074, KL Div: 3224.9995\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 9828.9189, KL Div: 3258.6672\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 10030.3955, KL Div: 3213.9338\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 9777.0508, KL Div: 3226.8940\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10352.7178, KL Div: 3196.4902\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 9935.6777, KL Div: 3254.8184\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 10818.7598, KL Div: 3390.0581\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 10260.5879, KL Div: 3281.7314\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10507.2070, KL Div: 3243.2393\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 10510.5938, KL Div: 3351.2551\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 10289.3623, KL Div: 3332.9614\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 10281.6543, KL Div: 3275.9019\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10158.8613, KL Div: 3210.9719\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 10006.0889, KL Div: 3201.1633\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 10621.9775, KL Div: 3357.3318\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10254.0137, KL Div: 3264.6775\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 10514.9238, KL Div: 3343.1416\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 10211.0596, KL Div: 3328.4580\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 10516.6699, KL Div: 3216.2710\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10234.6377, KL Div: 3244.6812\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 10043.9668, KL Div: 3239.0510\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 9759.7285, KL Div: 3226.2012\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10248.8906, KL Div: 3349.3413\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 9819.9951, KL Div: 3248.4216\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10465.1777, KL Div: 3315.6348\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 10265.2578, KL Div: 3232.9453\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10919.4209, KL Div: 3363.8335\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 10070.5732, KL Div: 3260.6648\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 10010.1367, KL Div: 3170.9146\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 9995.9277, KL Div: 3265.5073\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 10215.4355, KL Div: 3279.9500\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 10486.5889, KL Div: 3287.1372\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 9756.6143, KL Div: 3222.9749\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 10310.5645, KL Div: 3297.9553\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 9947.1504, KL Div: 3295.3882\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 10205.0371, KL Div: 3161.7886\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 10900.3066, KL Div: 3339.9517\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 10632.2920, KL Div: 3324.3701\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 10097.9980, KL Div: 3258.3704\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 9945.4736, KL Div: 3363.3833\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 9795.4229, KL Div: 3210.4766\n",
      "Epoch[15/15], Step [370/469], Reconst Loss: 10020.1035, KL Div: 3304.8679\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 10183.8105, KL Div: 3349.1187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/15], Step [390/469], Reconst Loss: 10398.4590, KL Div: 3281.9751\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10013.5781, KL Div: 3154.8486\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 10103.8857, KL Div: 3260.9517\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 10115.5000, KL Div: 3252.0024\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 9815.9463, KL Div: 3210.5952\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 9961.9756, KL Div: 3264.4841\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10143.5977, KL Div: 3259.7280\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 10205.9180, KL Div: 3162.0981\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
