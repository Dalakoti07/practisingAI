{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 28 * 28    # 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9912422 [02:05<?, ?it/s]\u001b[A\n",
      "  0%|          | 16384/9912422 [02:05<02:47, 59230.36it/s]\u001b[A\n",
      "  1%|          | 81920/9912422 [02:05<02:07, 77266.37it/s]\u001b[A\n",
      "  1%|          | 98304/9912422 [02:06<02:05, 78075.11it/s]\u001b[A\n",
      "  1%|▏         | 147456/9912422 [02:06<01:37, 100006.10it/s]\u001b[A\n",
      "  2%|▏         | 212992/9912422 [02:06<01:19, 122451.04it/s]\u001b[A\n",
      "  4%|▎         | 352256/9912422 [02:06<00:56, 168331.16it/s]\u001b[A\n",
      "  4%|▍         | 409600/9912422 [02:06<00:52, 181070.11it/s]\u001b[A\n",
      "  6%|▌         | 573440/9912422 [02:07<00:41, 227211.19it/s]\u001b[A\n",
      "  7%|▋         | 663552/9912422 [02:07<00:32, 282485.07it/s]\u001b[A\n",
      "  8%|▊         | 778240/9912422 [02:07<00:28, 317708.66it/s]\u001b[A\n",
      "  9%|▉         | 901120/9912422 [02:07<00:23, 375494.10it/s]\u001b[A\n",
      " 11%|█         | 1089536/9912422 [02:08<00:20, 429086.03it/s]\u001b[A\n",
      " 12%|█▏        | 1236992/9912422 [02:08<00:18, 473433.74it/s]\u001b[A\n",
      " 14%|█▍        | 1425408/9912422 [02:08<00:13, 606612.06it/s]\u001b[A\n",
      " 15%|█▌        | 1523712/9912422 [02:08<00:16, 502399.11it/s]\u001b[A\n",
      " 16%|█▌        | 1605632/9912422 [02:09<00:19, 421744.36it/s]\u001b[A\n",
      " 18%|█▊        | 1802240/9912422 [02:09<00:18, 444194.58it/s]\u001b[A\n",
      " 20%|█▉        | 1957888/9912422 [02:09<00:16, 482644.44it/s]\u001b[A\n",
      " 22%|██▏       | 2228224/9912422 [02:09<00:13, 584248.86it/s]\u001b[A\n",
      " 23%|██▎       | 2310144/9912422 [02:10<00:14, 532452.84it/s]\u001b[A\n",
      " 24%|██▍       | 2383872/9912422 [02:10<00:13, 572592.98it/s]\u001b[A\n",
      " 27%|██▋       | 2662400/9912422 [02:10<00:09, 748647.49it/s]\u001b[A\n",
      " 28%|██▊       | 2793472/9912422 [02:10<00:09, 749307.18it/s]\u001b[A\n",
      " 29%|██▉       | 2908160/9912422 [02:10<00:12, 552117.76it/s]\u001b[A\n",
      " 31%|███       | 3080192/9912422 [02:10<00:09, 692030.34it/s]\u001b[A\n",
      " 32%|███▏      | 3194880/9912422 [02:12<00:27, 244740.80it/s]\u001b[A\n",
      " 33%|███▎      | 3276800/9912422 [02:12<00:24, 267139.91it/s]\u001b[A\n",
      " 34%|███▍      | 3350528/9912422 [02:12<00:27, 242372.01it/s]\u001b[A\n",
      " 35%|███▌      | 3506176/9912422 [02:13<00:22, 282290.01it/s]\u001b[A\n",
      " 38%|███▊      | 3792896/9912422 [02:13<00:17, 355504.05it/s]\u001b[A\n",
      " 42%|████▏     | 4194304/9912422 [02:13<00:12, 467288.43it/s]\u001b[A\n",
      " 44%|████▍     | 4358144/9912422 [02:13<00:09, 588572.29it/s]\u001b[A\n",
      " 45%|████▌     | 4472832/9912422 [02:13<00:08, 670787.42it/s]\u001b[A\n",
      " 46%|████▋     | 4587520/9912422 [02:13<00:07, 741130.75it/s]\u001b[A\n",
      " 47%|████▋     | 4694016/9912422 [02:14<00:07, 720337.31it/s]\u001b[A\n",
      " 49%|████▉     | 4882432/9912422 [02:14<00:05, 879566.97it/s]\u001b[A\n",
      " 50%|█████     | 5005312/9912422 [02:14<00:07, 613926.27it/s]\u001b[A\n",
      " 52%|█████▏    | 5136384/9912422 [02:14<00:07, 638016.90it/s]\u001b[A\n",
      " 55%|█████▍    | 5431296/9912422 [02:14<00:06, 732269.77it/s]\u001b[A\n",
      " 57%|█████▋    | 5668864/9912422 [02:15<00:04, 923303.12it/s]\u001b[A\n",
      " 59%|█████▊    | 5808128/9912422 [02:15<00:05, 738510.59it/s]\u001b[A\n",
      " 60%|█████▉    | 5922816/9912422 [02:15<00:04, 800952.61it/s]\u001b[A\n",
      " 61%|██████    | 6045696/9912422 [02:15<00:05, 735837.55it/s]\u001b[A\n",
      " 62%|██████▏   | 6160384/9912422 [02:15<00:05, 749279.43it/s]\u001b[A\n",
      " 63%|██████▎   | 6266880/9912422 [02:15<00:04, 805267.14it/s]\u001b[A\n",
      " 64%|██████▍   | 6365184/9912422 [02:16<00:04, 748898.84it/s]\u001b[A\n",
      " 66%|██████▌   | 6512640/9912422 [02:16<00:04, 835100.69it/s]\u001b[A\n",
      " 68%|██████▊   | 6766592/9912422 [02:16<00:03, 1018030.86it/s]\u001b[A\n",
      " 70%|██████▉   | 6897664/9912422 [02:16<00:02, 1080696.35it/s]\u001b[A\n",
      " 71%|███████   | 7028736/9912422 [02:16<00:02, 1091487.85it/s]\u001b[A\n",
      " 72%|███████▏  | 7151616/9912422 [02:16<00:02, 1125791.82it/s]\u001b[A\n",
      " 73%|███████▎  | 7274496/9912422 [02:16<00:02, 1124106.14it/s]\u001b[A\n",
      " 76%|███████▌  | 7495680/9912422 [02:16<00:02, 1096563.14it/s]\u001b[A\n",
      " 78%|███████▊  | 7774208/9912422 [02:17<00:01, 1329299.80it/s]\u001b[A\n",
      " 80%|████████  | 7938048/9912422 [02:17<00:03, 535912.39it/s] \u001b[A\n",
      " 82%|████████▏ | 8118272/9912422 [02:17<00:02, 677534.05it/s]\u001b[A\n",
      " 84%|████████▎ | 8290304/9912422 [02:18<00:02, 627853.02it/s]\u001b[A\n",
      " 86%|████████▋ | 8568832/9912422 [02:18<00:01, 766290.43it/s]\u001b[A\n",
      " 88%|████████▊ | 8699904/9912422 [02:18<00:01, 782728.76it/s]\u001b[A\n",
      " 90%|████████▉ | 8880128/9912422 [02:18<00:01, 935093.28it/s]\u001b[A\n",
      " 91%|█████████ | 9011200/9912422 [02:18<00:01, 868888.83it/s]\u001b[A\n",
      " 92%|█████████▏| 9125888/9912422 [02:19<00:01, 707667.08it/s]\u001b[A\n",
      " 94%|█████████▍| 9330688/9912422 [02:19<00:00, 695068.18it/s]\u001b[A\n",
      " 95%|█████████▌| 9461760/9912422 [02:19<00:00, 457184.63it/s]\u001b[A\n",
      " 99%|█████████▉| 9822208/9912422 [02:20<00:00, 597318.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9920512it [02:34, 597318.13it/s]                             \u001b[A\n",
      "\n",
      "  0%|          | 0/28881 [02:06<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 16384/28881 [02:06<00:00, 53457.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "32768it [02:23, 53457.14it/s]                           \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1648877 [02:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 8192/1648877 [02:06<01:01, 26577.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 40960/1648877 [02:06<00:45, 35469.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▍         | 81920/1648877 [02:06<00:33, 46517.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 139264/1648877 [02:07<00:23, 63962.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|▉         | 163840/1648877 [02:07<00:20, 72576.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 237568/1648877 [02:07<00:14, 95750.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 311296/1648877 [02:07<00:10, 124595.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 368640/1648877 [02:07<00:08, 150529.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 581632/1648877 [02:08<00:06, 158568.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 704512/1648877 [02:09<00:04, 199576.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████     | 835584/1648877 [02:09<00:03, 253366.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▌    | 909312/1648877 [02:09<00:02, 291142.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████▊    | 958464/1648877 [02:09<00:02, 298985.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|██████▎   | 1048576/1648877 [02:09<00:01, 352842.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 1155072/1648877 [02:10<00:01, 435683.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▍ | 1400832/1648877 [02:10<00:00, 560135.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████ | 1499136/1648877 [02:10<00:00, 402968.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "1654784it [02:27, 402968.44it/s]                             \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4542 [02:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset (images and labels)\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Logistic regression model\n",
    "model = nn.Linear(input_size, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "# nn.CrossEntropyLoss() computes softmax internally\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 2.2082\n",
      "Epoch [1/5], Step [200/600], Loss: 2.1055\n",
      "Epoch [1/5], Step [300/600], Loss: 2.0247\n",
      "Epoch [1/5], Step [400/600], Loss: 1.9782\n",
      "Epoch [1/5], Step [500/600], Loss: 1.8780\n",
      "Epoch [1/5], Step [600/600], Loss: 1.8364\n",
      "Epoch [2/5], Step [100/600], Loss: 1.6578\n",
      "Epoch [2/5], Step [200/600], Loss: 1.6416\n",
      "Epoch [2/5], Step [300/600], Loss: 1.5659\n",
      "Epoch [2/5], Step [400/600], Loss: 1.5514\n",
      "Epoch [2/5], Step [500/600], Loss: 1.5099\n",
      "Epoch [2/5], Step [600/600], Loss: 1.3949\n",
      "Epoch [3/5], Step [100/600], Loss: 1.4519\n",
      "Epoch [3/5], Step [200/600], Loss: 1.4715\n",
      "Epoch [3/5], Step [300/600], Loss: 1.4044\n",
      "Epoch [3/5], Step [400/600], Loss: 1.2014\n",
      "Epoch [3/5], Step [500/600], Loss: 1.2219\n",
      "Epoch [3/5], Step [600/600], Loss: 1.2493\n",
      "Epoch [4/5], Step [100/600], Loss: 1.2780\n",
      "Epoch [4/5], Step [200/600], Loss: 1.1982\n",
      "Epoch [4/5], Step [300/600], Loss: 1.1700\n",
      "Epoch [4/5], Step [400/600], Loss: 1.1935\n",
      "Epoch [4/5], Step [500/600], Loss: 1.1670\n",
      "Epoch [4/5], Step [600/600], Loss: 1.1358\n",
      "Epoch [5/5], Step [100/600], Loss: 1.1351\n",
      "Epoch [5/5], Step [200/600], Loss: 1.0833\n",
      "Epoch [5/5], Step [300/600], Loss: 1.0527\n",
      "Epoch [5/5], Step [400/600], Loss: 1.0815\n",
      "Epoch [5/5], Step [500/600], Loss: 0.9994\n",
      "Epoch [5/5], Step [600/600], Loss: 1.1588\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        images = images.reshape(-1, input_size)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, input_size)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
