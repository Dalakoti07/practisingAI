{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments with pytorch",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Lzggzt0dgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "06ceeb1a-a0fa-46fe-ab1d-728eb3c6d6aa"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Creating the graph\n",
        "x = torch.tensor(1.0, requires_grad = True)\n",
        "y = torch.tensor(2.0)\n",
        "z = x * y\n",
        "\n",
        "# Displaying\n",
        "for i, name in zip([x, y, z], \"xyz\"):\n",
        "    print(f\"{name}\\ndata: {i.data}\\nrequires_grad: {i.requires_grad}\\n\\\n",
        "grad: {i.grad}\\ngrad_fn: {i.grad_fn}\\nis_leaf: {i.is_leaf}\\n\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x\n",
            "data: 1.0\n",
            "requires_grad: True\n",
            "grad: None\n",
            "grad_fn: None\n",
            "is_leaf: True\n",
            "\n",
            "y\n",
            "data: 2.0\n",
            "requires_grad: False\n",
            "grad: None\n",
            "grad_fn: None\n",
            "is_leaf: True\n",
            "\n",
            "z\n",
            "data: 2.0\n",
            "requires_grad: True\n",
            "grad: None\n",
            "grad_fn: <MulBackward0 object at 0x7ff12f4b6940>\n",
            "is_leaf: False\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Pl86k3hdB5",
        "colab_type": "text"
      },
      "source": [
        "Every variable object has several members some of which are:\n",
        "\n",
        "**Data** : It’s the data a variable is holding. x holds a 1x1 tensor with the value equal to 1.0 while y holds 2.0. z holds the product of two i.e. 2.0\n",
        "\n",
        "**requires_grad**: This member, if true starts tracking all the operation history and forms a backward graph for gradient calculation. For an arbitrary tensor a It can be manipulated in-place as follows: a.requires_grad_(True).\n",
        "\n",
        "**grad**: grad holds the value of gradient. If requires_grad is False it will hold a None value. Even if requires_grad is True, it will hold a None value unless .backward() function is called from some other node. For example, if you call out.backward() for some variable out that involved x in its calculations then x.grad will hold ∂out/∂x.\n",
        "\n",
        "**grad_fn**: This is the backward function used to calculate the gradient.\n",
        "\n",
        "**is_leaf**: A node is leaf if :\n",
        "\n",
        "It was initialized explicitly by some function like x = torch.tensor(1.0) or x = torch.randn(1, 1) (basically all the tensor initializing methods discussed at the beginning of this post).\n",
        "\n",
        "It is created after operations on tensors which all have requires_grad = False.\n",
        "\n",
        "It is created by calling .detach() method on some tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_nFlpDH0ykh",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/589/1*viCEZbSODfA8ZA4ECPwHxQ.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iq-zWmD0xb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wqlVLzn1_2L",
        "colab_type": "text"
      },
      "source": [
        "### get insight from this blog\n",
        "\n",
        "https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRknrLyzh66G",
        "colab_type": "text"
      },
      "source": [
        "To stop PyTorch from tracking the history and forming the backward graph, the code can be wrapped inside with torch.no_grad(): It will make the code run faster whenever gradient tracking is not needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv3Dced20xlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f4a69e29-c814-4221-a7a2-c8e3a915dbd5"
      },
      "source": [
        "import torch\n",
        "# Creating the graph\n",
        "x = torch.tensor(1.0, requires_grad = True)\n",
        "# Check if tracking is enabled\n",
        "print(x.requires_grad) #True\n",
        "y = x * 2\n",
        "print(y.requires_grad) #True\n",
        "\n",
        "with torch.no_grad():\n",
        "\t# Check if tracking is enabled\n",
        "\ty = x * 2\n",
        "\tprint(y.requires_grad) #False"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SmrJ_ugiAn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aacd3bb-f822-4713-a420-3b156fd0de32"
      },
      "source": [
        "import torch\n",
        "# Creating the graph\n",
        "x = torch.tensor(1.0, requires_grad = True)\n",
        "z = x ** 3\n",
        "z.backward() #Computes the gradient \n",
        "print(x.grad.data) #Prints '3' which is dz/dx "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glfgl0BkiInH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}