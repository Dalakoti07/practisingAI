{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LoanAmount            Loan amount in thousands\n",
    "\n",
    "Loan_Amount_Term      Term of loan in months\n",
    "\n",
    "Credit_History        Credit history meets guidelines\n",
    "\n",
    "Property_Area         Urban/ Semi Urban/ Rural\n",
    "\n",
    "Loan_Status           Loan approved (Y/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               object\n",
       "Gender                object\n",
       "Married               object\n",
       "Dependents            object\n",
       "Education             object\n",
       "Self_Employed         object\n",
       "ApplicantIncome        int64\n",
       "CoapplicantIncome    float64\n",
       "LoanAmount           float64\n",
       "Loan_Amount_Term     float64\n",
       "Credit_History       float64\n",
       "Property_Area         object\n",
       "Loan_Status           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data for the ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dealing with nans\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "list_encoders=[]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "coulmns=None\n",
    "scalar=None\n",
    "means=None\n",
    "def preProcessDataTrain(train):\n",
    "    global means, scalar\n",
    "# High Nans in gender, married, dependents, self_employed, loanAmount, loanTerms, credit_history\n",
    "    NaColsCats=['Gender','Married','Dependents','Self_Employed']\n",
    "#     for x in NaColsCats:\n",
    "#         print(train[x].value_counts(),end='\\n\\n')\n",
    "    train['Gender']=train['Gender'].fillna('Male')\n",
    "    train['Married']=train['Married'].fillna('Yes')\n",
    "    train['Dependents']=train['Dependents'].fillna('0')\n",
    "    train['Self_Employed']=train['Self_Employed'].fillna('No')\n",
    "#     filling the nas with mean for numeric real values\n",
    "    means=train.mean()\n",
    "    train=train.fillna(train.mean())\n",
    "    global list_encoders\n",
    "    global columns\n",
    "    columns=['Gender','Married','Education','Self_Employed','Property_Area']\n",
    "    for c in columns:\n",
    "        cEncoder=LabelEncoder()\n",
    "        train[c]=cEncoder.fit_transform(train[c].astype('str'))\n",
    "        list_encoders.append(cEncoder)\n",
    "    \n",
    "#     coverting 3+ in train to 3\n",
    "    train['Dependents']=train['Dependents'].replace(['3+'], '3')\n",
    "    train['Loan_Status']=train['Loan_Status'].replace(['Y','N'],[1,0])\n",
    "    # coverting dependents column to integer\n",
    "    train['Dependents']=train['Dependents'].astype(str).astype(int)\n",
    "    \n",
    "#     no one hot encode the columns \n",
    "    col_to_one_hot=['Gender','Married','Education','Self_employed']\n",
    "#     I dont think there is some need to one hot the columns, It would introduce the co linearity in the dataset\n",
    "    \n",
    "    train.drop(['Loan_ID'],axis=1,inplace=True)\n",
    "    scaler = StandardScaler()\n",
    "    train_big_num=train[['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']]\n",
    "    scaler.fit(train_big_num)\n",
    "#     print(scaler.mean_)\n",
    "\n",
    "    train_np=scaler.transform(train_big_num)\n",
    "    \n",
    "    scaled_features=pd.DataFrame(data=train_np,columns=['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term'])\n",
    "    \n",
    "    sc_feat=['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']\n",
    "    for sf in sc_feat:\n",
    "        train[sf]=scaled_features[sf]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us one Hot encode some of the columns because numeric assignmnet does not make a sense\n",
    "\n",
    "Columns are Gender, Married, Education, Self_employed\n",
    "\n",
    "\n",
    "\n",
    "I prefer using sklearn.preprocessing.OneHotEncoder instead of pd.get_dummies This is because sklearn.preprocessing.OneHotEncoder returns an object of sklearn.preprocessing.OneHotEncoder class. We can fit this object on the training set and then use the same object to transform the test set. On the other hand, pd.get_dummies returns a dataframe with encodings based on the values in the dataframe we pass to it. This might be good for a quick analysis, but for an extended model building project where you train on training set and will be later testing on a test set, I would suggest using sklearn.preprocessing.OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp=preProcessDataTrain(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes are  ['Female' 'Male']  in  Gender\n",
      "classes are  ['No' 'Yes']  in  Married\n",
      "classes are  ['Graduate' 'Not Graduate']  in  Education\n",
      "classes are  ['No' 'Yes']  in  Self_Employed\n",
      "classes are  ['Rural' 'Semiurban' 'Urban']  in  Property_Area\n"
     ]
    }
   ],
   "source": [
    "# seeing all the lebels\n",
    "for x,c in zip(list_encoders,columns):\n",
    "    print('classes are ',x.classes_,' in ',c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072991</td>\n",
       "      <td>-0.554487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.134412</td>\n",
       "      <td>-0.038732</td>\n",
       "      <td>-0.219273</td>\n",
       "      <td>0.279851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.393747</td>\n",
       "      <td>-0.554487</td>\n",
       "      <td>-0.957641</td>\n",
       "      <td>0.279851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.462062</td>\n",
       "      <td>0.251980</td>\n",
       "      <td>-0.314547</td>\n",
       "      <td>0.279851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097728</td>\n",
       "      <td>-0.554487</td>\n",
       "      <td>-0.064454</td>\n",
       "      <td>0.279851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0       1        0           0          0              0         0.072991   \n",
       "1       1        1           1          0              0        -0.134412   \n",
       "2       1        1           0          0              1        -0.393747   \n",
       "3       1        1           0          1              0        -0.462062   \n",
       "4       1        0           0          0              0         0.097728   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0          -0.554487    0.000000          0.279851             1.0   \n",
       "1          -0.038732   -0.219273          0.279851             1.0   \n",
       "2          -0.554487   -0.957641          0.279851             1.0   \n",
       "3           0.251980   -0.314547          0.279851             1.0   \n",
       "4          -0.554487   -0.064454          0.279851             1.0   \n",
       "\n",
       "   Property_Area  Loan_Status  \n",
       "0              2            1  \n",
       "1              0            0  \n",
       "2              2            1  \n",
       "3              2            1  \n",
       "4              2            1  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_pp.drop(['Loan_Status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=train_pp[['Loan_Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1\n",
    "\n",
    "Making Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc is  0.8150851581508516\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='warn', n_jobs=1, penalty='l1', random_state=0,\n",
      "                   solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "test acc is  0.7980295566502463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_lr = LogisticRegression(penalty='l1',random_state=0,solver='liblinear',max_iter=1000,n_jobs=1)\n",
    "clf_lr=clf_lr.fit(x_train, np.squeeze(y_train.values))\n",
    "train_preds=clf_lr.predict(x_train)\n",
    "train_acc=accuracy_score(y_train, train_preds)\n",
    "print('train acc is ',train_acc)\n",
    "\n",
    "print(clf_lr)\n",
    "\n",
    "test_preds=clf_lr.predict(x_test)\n",
    "test_acc=accuracy_score(y_test,test_preds)\n",
    "print('test acc is ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('lr.txt',train_preds,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l1 and l2 both are giving same 81% accuracy, not much accuracy but very less overfitting\n",
    "\n",
    "##### Model 2\n",
    "Let us try SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][[-6.44487109e-09  7.30808215e-10 -3.21991480e-09 -2.44938056e-09\n",
      "  -3.29407207e-09  6.29762123e-09  7.40012711e-09 -7.91761123e-11\n",
      "  -3.04565902e-10  1.99999998e+00 -4.09429552e-09]]\n",
      "[-0.99999998]\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
      "          penalty='l2', random_state=0, tol=1e-05, verbose=1)\n",
      "train acc is  0.8150851581508516\n",
      "test acc is  0.7980295566502463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_svm = LinearSVC(tol=1e-5,penalty='l2',loss='hinge',dual=True,C=1.0,verbose=1,random_state=0,max_iter=1000)\n",
    "# C,max_iter to be tuned\n",
    "\n",
    "clf_svm=clf_svm.fit(x_train, np.squeeze(y_train.values))  \n",
    "print(clf_svm.coef_)\n",
    "print(clf_svm.intercept_)\n",
    "\n",
    "print(clf_svm)\n",
    "\n",
    "train_preds=clf_svm.predict(x_train)\n",
    "train_acc=accuracy_score(y_train, train_preds)\n",
    "print('train acc is ',train_acc)\n",
    "\n",
    "\n",
    "test_preds=clf_svm.predict(x_test)\n",
    "test_acc=accuracy_score(y_test,test_preds)\n",
    "print('test acc is ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('svm.txt',train_preds,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not any good results from SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3 Naive Bayes\n",
    "\n",
    "Provide a good base Model in classification, let us see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "<bound method BaseEstimator.get_params of GaussianNB(priors=None, var_smoothing=1e-09)>\n",
      "train acc is  0.8126520681265207\n",
      "test acc is  0.7980295566502463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf_nb = GaussianNB()\n",
    "print(clf_nb)\n",
    "clf_nb=clf_nb.fit(x_train, np.squeeze(y_train.values))  \n",
    "\n",
    "print(clf_nb)\n",
    "\n",
    "print(clf_nb.get_params)\n",
    "\n",
    "train_preds=clf_nb.predict(x_train)\n",
    "train_acc=accuracy_score(y_train, train_preds)\n",
    "print('train acc is ',train_acc)\n",
    "\n",
    "\n",
    "test_preds=clf_nb.predict(x_test)\n",
    "test_acc=accuracy_score(y_test,test_preds)\n",
    "print('test acc is ',test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('nb.txt',train_preds,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 4 Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03049242 0.01286038 0.02916536 0.00941581 0.04846864 0.27632876\n",
      " 0.0783027  0.15419148 0.03143154 0.28487976 0.04446317]\n",
      "\n",
      "\n",
      "train acc is  1.0\n",
      "test acc is  0.6798029556650246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "# print(clf)\n",
    "clf=clf.fit(x_train,np.squeeze(y_train.values))\n",
    "print(clf.feature_importances_,end='\\n\\n\\n')\n",
    "train_preds=clf.predict(x_train)\n",
    "train_acc=accuracy_score(y_train, train_preds)\n",
    "print('train acc is ',train_acc)\n",
    "\n",
    "\n",
    "test_preds=clf.predict(x_test)\n",
    "test_acc=accuracy_score(y_test,test_preds)\n",
    "print('test acc is ',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27, 15 and 28% are top 3 feature contribution, and lots of overfitting let us do some regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_.sum()\n",
    "# and they sum to 99.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 11)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(103.80708469055375, 211.7178947368421, 'X[9] <= 0.421\\nentropy = 0.413\\nsamples = 411\\nvalue = [120, 291]'),\n",
       " Text(57.799348534201954, 200.2736842105263, 'X[6] <= 2.221\\nentropy = 0.168\\nsamples = 54\\nvalue = [49, 5]'),\n",
       " Text(53.437133550488596, 188.82947368421054, 'X[5] <= -0.178\\nentropy = 0.14\\nsamples = 53\\nvalue = [49, 4]'),\n",
       " Text(44.71270358306189, 177.38526315789474, 'X[8] <= -1.586\\nentropy = 0.057\\nsamples = 34\\nvalue = [33, 1]'),\n",
       " Text(40.35048859934854, 165.94105263157894, 'X[5] <= -0.468\\nentropy = 0.245\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(35.98827361563518, 154.49684210526317, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(44.71270358306189, 154.49684210526317, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(49.074918566775246, 165.94105263157894, 'entropy = 0.0\\nsamples = 27\\nvalue = [27, 0]'),\n",
       " Text(62.16156351791531, 177.38526315789474, 'X[5] <= -0.063\\nentropy = 0.266\\nsamples = 19\\nvalue = [16, 3]'),\n",
       " Text(57.799348534201954, 165.94105263157894, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(66.52377850162867, 165.94105263157894, 'entropy = 0.0\\nsamples = 16\\nvalue = [16, 0]'),\n",
       " Text(62.16156351791531, 188.82947368421054, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(149.81482084690555, 200.2736842105263, 'X[1] <= 0.5\\nentropy = 0.319\\nsamples = 357\\nvalue = [71, 286]'),\n",
       " Text(91.60651465798045, 188.82947368421054, 'X[8] <= -4.571\\nentropy = 0.395\\nsamples = 133\\nvalue = [36, 97]'),\n",
       " Text(87.2442996742671, 177.38526315789474, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(95.96872964169381, 177.38526315789474, 'X[5] <= 0.102\\nentropy = 0.384\\nsamples = 131\\nvalue = [34, 97]'),\n",
       " Text(75.24820846905537, 165.94105263157894, 'X[8] <= 1.213\\nentropy = 0.344\\nsamples = 104\\nvalue = [23, 81]'),\n",
       " Text(64.34267100977199, 154.49684210526317, 'X[5] <= -0.577\\nentropy = 0.32\\nsamples = 100\\nvalue = [20, 80]'),\n",
       " Text(55.618241042345275, 143.05263157894737, 'X[7] <= -0.886\\nentropy = 0.48\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(51.256026058631925, 131.60842105263157, 'X[7] <= -1.255\\nentropy = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(46.89381107491857, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(55.618241042345275, 120.16421052631578, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(59.98045602605863, 131.60842105263157, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(73.06710097719869, 143.05263157894737, 'X[6] <= 0.173\\nentropy = 0.294\\nsamples = 95\\nvalue = [17, 78]'),\n",
       " Text(68.70488599348535, 131.60842105263157, 'X[5] <= -0.109\\nentropy = 0.347\\nsamples = 76\\nvalue = [17, 59]'),\n",
       " Text(64.34267100977199, 120.16421052631578, 'X[5] <= -0.129\\nentropy = 0.386\\nsamples = 65\\nvalue = [17, 48]'),\n",
       " Text(52.346579804560264, 108.72, 'X[4] <= 0.5\\nentropy = 0.339\\nsamples = 60\\nvalue = [13, 47]'),\n",
       " Text(41.44104234527687, 97.27578947368421, 'X[5] <= -0.294\\nentropy = 0.311\\nsamples = 57\\nvalue = [11, 46]'),\n",
       " Text(32.71661237785016, 85.83157894736843, 'X[5] <= -0.296\\nentropy = 0.401\\nsamples = 36\\nvalue = [10, 26]'),\n",
       " Text(28.354397394136807, 74.38736842105263, 'X[7] <= -0.136\\nentropy = 0.36\\nsamples = 34\\nvalue = [8, 26]'),\n",
       " Text(17.44885993485342, 62.943157894736856, 'X[10] <= 0.5\\nentropy = 0.285\\nsamples = 29\\nvalue = [5, 24]'),\n",
       " Text(8.72442996742671, 51.49894736842106, 'X[7] <= -0.964\\nentropy = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(4.362214983713355, 40.05473684210526, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(13.086644951140066, 40.05473684210526, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(26.173289902280132, 51.49894736842106, 'X[0] <= 0.5\\nentropy = 0.204\\nsamples = 26\\nvalue = [3, 23]'),\n",
       " Text(21.811074918566774, 40.05473684210526, 'entropy = 0.0\\nsamples = 13\\nvalue = [0, 13]'),\n",
       " Text(30.535504885993486, 40.05473684210526, 'X[7] <= -0.88\\nentropy = 0.355\\nsamples = 13\\nvalue = [3, 10]'),\n",
       " Text(26.173289902280132, 28.610526315789485, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(34.89771986970684, 28.610526315789485, 'X[7] <= -0.588\\nentropy = 0.49\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(30.535504885993486, 17.166315789473686, 'X[6] <= -0.332\\nentropy = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(26.173289902280132, 5.722105263157886, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(34.89771986970684, 5.722105263157886, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(39.2599348534202, 17.166315789473686, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(39.2599348534202, 62.943157894736856, 'X[10] <= 1.0\\nentropy = 0.48\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(34.89771986970684, 51.49894736842106, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(43.62214983713355, 51.49894736842106, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(37.07882736156352, 74.38736842105263, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(50.165472312703585, 85.83157894736843, 'X[5] <= -0.195\\nentropy = 0.091\\nsamples = 21\\nvalue = [1, 20]'),\n",
       " Text(45.80325732899023, 74.38736842105263, 'entropy = 0.0\\nsamples = 15\\nvalue = [0, 15]'),\n",
       " Text(54.527687296416936, 74.38736842105263, 'X[7] <= -0.392\\nentropy = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(50.165472312703585, 62.943157894736856, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(58.88990228013029, 62.943157894736856, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(63.25211726384365, 97.27578947368421, 'X[7] <= -0.428\\nentropy = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(58.88990228013029, 85.83157894736843, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(67.614332247557, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(76.33876221498372, 108.72, 'X[3] <= 0.5\\nentropy = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(71.97654723127036, 97.27578947368421, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(80.70097719869707, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(73.06710097719869, 120.16421052631578, 'entropy = 0.0\\nsamples = 11\\nvalue = [0, 11]'),\n",
       " Text(77.42931596091205, 131.60842105263157, 'entropy = 0.0\\nsamples = 19\\nvalue = [0, 19]'),\n",
       " Text(86.15374592833876, 154.49684210526317, 'X[5] <= -0.628\\nentropy = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(81.7915309446254, 143.05263157894737, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(90.51596091205212, 143.05263157894737, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(116.68925081433224, 165.94105263157894, 'X[4] <= 0.5\\nentropy = 0.483\\nsamples = 27\\nvalue = [11, 16]'),\n",
       " Text(103.60260586319218, 154.49684210526317, 'X[0] <= 0.5\\nentropy = 0.459\\nsamples = 14\\nvalue = [9, 5]'),\n",
       " Text(99.24039087947882, 143.05263157894737, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(107.96482084690554, 143.05263157894737, 'X[5] <= 0.616\\nentropy = 0.298\\nsamples = 11\\nvalue = [9, 2]'),\n",
       " Text(103.60260586319218, 131.60842105263157, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(112.3270358306189, 131.60842105263157, 'X[5] <= 0.787\\nentropy = 0.444\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(107.96482084690554, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(116.68925081433224, 120.16421052631578, 'X[7] <= 2.573\\nentropy = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(112.3270358306189, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(121.0514657980456, 108.72, 'X[7] <= 3.526\\nentropy = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(116.68925081433224, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(125.41368078175896, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(129.7758957654723, 154.49684210526317, 'X[5] <= 0.135\\nentropy = 0.26\\nsamples = 13\\nvalue = [2, 11]'),\n",
       " Text(125.41368078175896, 143.05263157894737, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(134.13811074918567, 143.05263157894737, 'X[10] <= 0.5\\nentropy = 0.153\\nsamples = 12\\nvalue = [1, 11]'),\n",
       " Text(129.7758957654723, 131.60842105263157, 'X[0] <= 0.5\\nentropy = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(125.41368078175896, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(134.13811074918567, 120.16421052631578, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(138.50032573289903, 131.60842105263157, 'entropy = 0.0\\nsamples = 9\\nvalue = [0, 9]'),\n",
       " Text(208.0231270358306, 188.82947368421054, 'X[10] <= 0.5\\nentropy = 0.264\\nsamples = 224\\nvalue = [35, 189]'),\n",
       " Text(153.76807817589577, 177.38526315789474, 'X[7] <= -0.678\\nentropy = 0.387\\nsamples = 61\\nvalue = [16, 45]'),\n",
       " Text(145.04364820846905, 165.94105263157894, 'X[5] <= -0.451\\nentropy = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(140.6814332247557, 154.49684210526317, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(149.4058631921824, 154.49684210526317, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(162.49250814332248, 165.94105263157894, 'X[5] <= -0.789\\nentropy = 0.337\\nsamples = 56\\nvalue = [12, 44]'),\n",
       " Text(158.13029315960912, 154.49684210526317, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(166.85472312703584, 154.49684210526317, 'X[2] <= 2.5\\nentropy = 0.32\\nsamples = 55\\nvalue = [11, 44]'),\n",
       " Text(162.49250814332248, 143.05263157894737, 'X[5] <= -0.354\\nentropy = 0.369\\nsamples = 45\\nvalue = [11, 34]'),\n",
       " Text(147.22475570032574, 131.60842105263157, 'X[6] <= 0.094\\nentropy = 0.153\\nsamples = 12\\nvalue = [1, 11]'),\n",
       " Text(142.8625407166124, 120.16421052631578, 'X[7] <= -0.231\\nentropy = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(138.50032573289903, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(147.22475570032574, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(151.58697068403907, 120.16421052631578, 'entropy = 0.0\\nsamples = 10\\nvalue = [0, 10]'),\n",
       " Text(177.76026058631922, 131.60842105263157, 'X[5] <= -0.08\\nentropy = 0.422\\nsamples = 33\\nvalue = [10, 23]'),\n",
       " Text(164.67361563517915, 120.16421052631578, 'X[2] <= 0.5\\nentropy = 0.497\\nsamples = 13\\nvalue = [7, 6]'),\n",
       " Text(155.94918566775243, 108.72, 'X[5] <= -0.323\\nentropy = 0.469\\nsamples = 8\\nvalue = [3, 5]'),\n",
       " Text(151.58697068403907, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(160.3114006514658, 97.27578947368421, 'X[5] <= -0.144\\nentropy = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(155.94918566775243, 85.83157894736843, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(164.67361563517915, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(173.39804560260586, 108.72, 'X[4] <= 0.5\\nentropy = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(169.0358306188925, 97.27578947368421, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(177.76026058631922, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(190.8469055374593, 120.16421052631578, 'X[7] <= 0.412\\nentropy = 0.255\\nsamples = 20\\nvalue = [3, 17]'),\n",
       " Text(186.48469055374593, 108.72, 'entropy = 0.0\\nsamples = 11\\nvalue = [0, 11]'),\n",
       " Text(195.20912052117265, 108.72, 'X[5] <= 0.266\\nentropy = 0.444\\nsamples = 9\\nvalue = [3, 6]'),\n",
       " Text(186.48469055374593, 97.27578947368421, 'X[7] <= 0.626\\nentropy = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(182.12247557003258, 85.83157894736843, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(190.8469055374593, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(203.93355048859934, 97.27578947368421, 'X[5] <= 1.512\\nentropy = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(199.57133550488598, 85.83157894736843, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(208.2957654723127, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(171.2169381107492, 143.05263157894737, 'entropy = 0.0\\nsamples = 10\\nvalue = [0, 10]'),\n",
       " Text(262.27817589576546, 177.38526315789474, 'X[6] <= 4.252\\nentropy = 0.206\\nsamples = 163\\nvalue = [19, 144]'),\n",
       " Text(257.9159609120521, 165.94105263157894, 'X[6] <= -0.522\\nentropy = 0.198\\nsamples = 162\\nvalue = [18, 144]'),\n",
       " Text(230.10684039087948, 154.49684210526317, 'X[9] <= 0.921\\nentropy = 0.316\\nsamples = 56\\nvalue = [11, 45]'),\n",
       " Text(225.74462540716613, 143.05263157894737, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(234.46905537459284, 143.05263157894737, 'X[7] <= -0.154\\nentropy = 0.298\\nsamples = 55\\nvalue = [10, 45]'),\n",
       " Text(217.0201954397394, 131.60842105263157, 'X[7] <= -0.928\\nentropy = 0.147\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(208.2957654723127, 120.16421052631578, 'X[10] <= 1.5\\nentropy = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(203.93355048859934, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(212.65798045602605, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(225.74462540716613, 120.16421052631578, 'X[10] <= 1.5\\nentropy = 0.083\\nsamples = 23\\nvalue = [1, 22]'),\n",
       " Text(221.38241042345277, 108.72, 'entropy = 0.0\\nsamples = 14\\nvalue = [0, 14]'),\n",
       " Text(230.10684039087948, 108.72, 'X[5] <= -0.127\\nentropy = 0.198\\nsamples = 9\\nvalue = [1, 8]'),\n",
       " Text(225.74462540716613, 97.27578947368421, 'X[5] <= -0.161\\nentropy = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(221.38241042345277, 85.83157894736843, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(230.10684039087948, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(234.46905537459284, 97.27578947368421, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(251.91791530944624, 131.60842105263157, 'X[5] <= -0.125\\nentropy = 0.391\\nsamples = 30\\nvalue = [8, 22]'),\n",
       " Text(247.5557003257329, 120.16421052631578, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(256.28013029315963, 120.16421052631578, 'X[5] <= 1.982\\nentropy = 0.337\\nsamples = 28\\nvalue = [6, 22]'),\n",
       " Text(247.5557003257329, 108.72, 'X[5] <= 0.579\\nentropy = 0.278\\nsamples = 24\\nvalue = [4, 20]'),\n",
       " Text(243.19348534201956, 97.27578947368421, 'X[4] <= 0.5\\nentropy = 0.444\\nsamples = 12\\nvalue = [4, 8]'),\n",
       " Text(238.8312703583062, 85.83157894736843, 'X[2] <= 0.5\\nentropy = 0.32\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " Text(234.46905537459284, 74.38736842105263, 'X[5] <= 0.241\\nentropy = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(230.10684039087948, 62.943157894736856, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(238.8312703583062, 62.943157894736856, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(243.19348534201956, 74.38736842105263, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
       " Text(247.5557003257329, 85.83157894736843, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(251.91791530944624, 97.27578947368421, 'entropy = 0.0\\nsamples = 12\\nvalue = [0, 12]'),\n",
       " Text(265.00456026058635, 108.72, 'X[7] <= 4.806\\nentropy = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(260.64234527687296, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(269.3667752442997, 97.27578947368421, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(285.7250814332248, 154.49684210526317, 'X[8] <= -1.586\\nentropy = 0.123\\nsamples = 106\\nvalue = [7, 99]'),\n",
       " Text(273.728990228013, 143.05263157894737, 'X[5] <= -0.462\\nentropy = 0.32\\nsamples = 15\\nvalue = [3, 12]'),\n",
       " Text(269.3667752442997, 131.60842105263157, 'X[6] <= 0.063\\nentropy = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(265.00456026058635, 120.16421052631578, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(273.728990228013, 120.16421052631578, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(278.0912052117264, 131.60842105263157, 'entropy = 0.0\\nsamples = 9\\nvalue = [0, 9]'),\n",
       " Text(297.7211726384365, 143.05263157894737, 'X[6] <= 0.278\\nentropy = 0.084\\nsamples = 91\\nvalue = [4, 87]'),\n",
       " Text(286.8156351791531, 131.60842105263157, 'X[7] <= -0.014\\nentropy = 0.032\\nsamples = 61\\nvalue = [1, 60]'),\n",
       " Text(282.4534201954397, 120.16421052631578, 'entropy = 0.0\\nsamples = 44\\nvalue = [0, 44]'),\n",
       " Text(291.17785016286643, 120.16421052631578, 'X[7] <= 0.009\\nentropy = 0.111\\nsamples = 17\\nvalue = [1, 16]'),\n",
       " Text(286.8156351791531, 108.72, 'X[2] <= 1.0\\nentropy = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(282.4534201954397, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(291.17785016286643, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(295.5400651465798, 108.72, 'entropy = 0.0\\nsamples = 15\\nvalue = [0, 15]'),\n",
       " Text(308.62671009771987, 131.60842105263157, 'X[6] <= 0.285\\nentropy = 0.18\\nsamples = 30\\nvalue = [3, 27]'),\n",
       " Text(304.26449511400654, 120.16421052631578, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(312.98892508143325, 120.16421052631578, 'X[5] <= -0.55\\nentropy = 0.128\\nsamples = 29\\nvalue = [2, 27]'),\n",
       " Text(304.26449511400654, 108.72, 'X[5] <= -0.576\\nentropy = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(299.90228013029315, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(308.62671009771987, 97.27578947368421, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(321.7133550488599, 108.72, 'X[7] <= 1.311\\nentropy = 0.071\\nsamples = 27\\nvalue = [1, 26]'),\n",
       " Text(317.3511400651466, 97.27578947368421, 'entropy = 0.0\\nsamples = 21\\nvalue = [0, 21]'),\n",
       " Text(326.0755700325733, 97.27578947368421, 'X[7] <= 1.335\\nentropy = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(321.7133550488599, 85.83157894736843, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(330.4377850162866, 85.83157894736843, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(266.64039087947884, 165.94105263157894, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO2de3QcWX3nP7elftmSLNmyJb/GyjBPD+PBM+PHhBnbsCGQDIQAu0uAELIbspvsLmcTnmF3z+7JQgghyckuJIRNAiEkIcnJnAAhEEISIj/EzAAzePAMYxuPRpY145YtS7IsW9WypLt/VFW7utXVdbu7uru6+/c5p49U3aXf/dW9t359dev+7ldprREEQRDqQ6zRDgiCILQTEnQFQRDqiARdQRCEOiJBVxAEoY5I0BUEQagjEnQFQRDqiARdQRCEOiJBVxAEoY5I0G0S0ul0Rimlg17pdDrTaF8FQfBHSUZac6CU0seOHaOzs5Pt27ezvLxMIpEgk8lgWRbr1q3jjjvuQCmF1lo12l9BEIojQbdJUErp6elpUqkU169fp6enx+88CbqCEGE6G+2AEIxSagPAiRMn8H5J9vb2orVGKTvGplKpxjgoCIIxMqcbQZRS/UqpNyqlPq6U+h7wPEAsFmNqagqlFEopBgcH2bhxIwCJRILbb7/d/fvvOX/7RqVUf8MuRBCEVcj0QgRQSm0EDjqvQ8BNwDeBYef1JLBo0lbOqHefY+cg8CAw7tg5DBzWWl8M039BEMyRoNsAlFKbyA+y24Fj2EFxGHhSa73k/ZtEInHp+vXr64Nsp1KpyYWFhUFPWZ3Abk9ZDwITnrIOa60vVHtNgiCYIUG3DiilBrgR9A4CW7GD7DB28PtuYZA1sNmntZ4Jeq/I33UAL3N8OYQdhM9zY1R9WGs9WY4vgiCYI0G3BiilBrkRZA8Bg9wIssPAca31cmO8y8cJwvdww9eHgAz5I+HzDXJPEFoOCbohoJTaTH6QHQCOciPIPhWVIBuEE4R3cWNUfgC4SP5I+MUGuScITY8E3QpQSm0lf052I3CEG6PD7zVLkA3CCcJ3c+NaDwCXyA/CLzTIPUFoOtoy6KbT6YxlWQN+n3sfRimlYsD9wK3cGP1twA6yw9iB9kSrBNkgnPp4KTdG9QeBaex6eBw4p7X+mnt+UF27FD4AFIRWpS2DrlJKl7pub1aXUuo3gfcCX+DG6O5prfVK7T2NPk4Qvgs7AP974GXejLiguvacJ5l0QlvQtkH36NGj3HzzzSwvL9PV1cXp06dJJBKk02nuvPNOb9BVQJfW+kqD3W5K3KA7PDzMpk2b6O3tze0bMTY2xuDgIDt27JCgK7QNbZsGvLi4yPHjx1m7di29vb0kk0nS6TSZTP4mXc4wTQJuFRw5coT5+XlWVlYYGxtj69atuXTms2fPcv369QZ7KAj1o21HuqbTC4IZzn8E24D7gHud133AYBmZdH8PPIGdgfckMG40NyEITUTbBt1HHnkkt2/B7bffztLSEmfOnOGhhx6io6NDgm4JnAD7Q+QH13uBZfKD5hPA2aNHjzI5ObmqvicmJli/fj233nqrG3R/kvygnfDYcu2NSiAWmpm2nV64//77mZiYoKurKxdwh4aGOHr0aKNdixTOg7JbyA+u9wLz3AiGn3B+ni8MiEoptm/fjlKKrq4u+vv7mZ2dZcuWLQC8+OKLrFmzBgCt9ZeAL3n+drOnvLcAvwX0KKW+S35wPy0PNoVmoS1HuuUsGWsnnDW5t5MfXHdjr8t1R5pPYqctG6UKh71kzNkcaHeBj5uA4wU+niw3tVoQ6kFbBl0ApdQh4H9prV/hHP859o36oYY6VieUUnFgJ/lTBLuw92HwjiKf1FpPN8pPE5RSfdiB2Dsa3wac4Ma1PAF8X2u92Cg/BQHaOOgWopT6GPC+VpzLVUolsRMavKPDu4Cz5M+ZfldrfblRfoaJUqoHe2Mf75fKDwHfJ/9L5YTW2mqUn0L7IUHXwXk4dLvW+mSjfakGpVQaewMbb7C5HThDfrB5Sms93yg/G4FSai32aN775XMbcJr8qYmntNbXGuWn0NpI0G1ilFJd3BjNuYHkJcCz5D/xP6G1XmiUn1FGKZXC3lvCW4c7gVHyA/FxSZARwqDlg67Jg5xGPDgr1y/n3+VfBJa4MUq7CXia/ODwjNY6W0vfWx2lVAJ7+sUbiO8GzmHX8feA9cAH3NUasseEYErLB10/6fJTp06xbt06ZmdnefWrX0026x+nanGjuH4tLS1x66235vw6e/YsWmsWFxc5cOCANx35A8BHubE860ngWa21pHPVAUeB407sAPxK4GeAm7TW55zPtdaakZERlpaW6OzspLu7G601CwsLKKXYt2+fJN4I7RF0g6TLlVIcPny4qNJuNptl//79od8opn7JDdocuEF3cnKSgYEBZmZm6OvrK3aetGmb0xbJEX7S5el0mvl5+1lSLBbLy5oaHBxkaWmJK1dqN43n51epUbcQHZyHrzuAvWDvMaG15uRJ+1ms255KKWZnZ9m8ebP7d/ux54hl1UQb0hZB1y+gZjIZ7rnnHgAefPDByPg1Pj5OZ2dbNE1ToZTaAOzBDrLuawl7H2Hf9pyamqK7u5vbbrvNNfV7wB1KqWeBb3leJyWzrvVpi+mFoGtMpVIlR5fJZPKiZVmb6u2X/CvaOJyld7vJD7Abge/gCZSuaka5+waXsP8E+YH4BdlrorVo+aBb6eoFr7KuicpuuZhIqsuT7vrgpD/fSX4AvB07kcIbAE/5jURNVy+U+gIvMZL2+vAdrfVsWRcoRIqWD7pKqSeAfuA2dymVG0SVUn+ArXaQaNS/dUqp92Hf8O/BlgH6AbAFsMIO9EJuHnY7+YHtXmwF5Me5EdyeqnbOtdiXdTlf4AVzxl5fJ8gPxE/JMsHmoR2C7ieBf9Raf6HIZ5uAzwOvasS/cM7C/GvAG5wdtlBKbRWhx/Bw9mUoHD2CHay+jR1ovxP1/SVcnKVrO7GvYx/2td2GvV7bG4hl57WI0vJBN8o4N9A3gB/TWl9ttD/NjvMl9jLyA+xm8udJHwcmWmme1ElvLpwfXs/q+ecXG+akkEOCrtCUOPv83kF+oNkJnCR/xPdsuyg1e3G2wCwc4Vusnh+ea5iTbUpTB92wUnyjkCrcLmmklVyn8x/BIPkB5D7gAvlB5LjsMVEcj9qHW397sEfH4+TX4fNa60vu37VLv6wnTR10w1p2Vc/lW0qpRLE9XdtFqryCpVWvBr4GXCT/Qdd3vMFBKB/ny+wu8r/MdgEf1Fp/1DmnLfplPWn6FfgjIyMsLCywc+fO3P4Fk5OTzMzMkEqljO0cO3YsJ8nu7s2glCKVSrFnz56q/fSOGBw9sKLXorXO8yOTyTA7O0tPTw+7d++u2o8oMDIyQk9PDxs2bMir72QyiWVZHDx40Hv6PwGvBb7aSvOwUcBR1njKef0hgFJqJ3Cq8Nzh4WHS6XRu/5JYLMbExAQAiUSijl43P00fdGdnZ0mn03ly6lrrsgIurJZk7+npQSmFZVk8//zzVftpWdZAqZjhpor6Xcvc3BynT5+u2o8oMDs7Szab5dy5c3n17SaonDt3LneuMx/7lQa52nZorb9f+N6RI0eYn59nZWWF48ePs3Xr1ly/nJ2dZdOmUPOGWh6ZXgjRTlAZfqq409PT7Nq1i3b4N07+XW0upL3Cp+lHuseOHSsayFw59WrtjI+Pc//994fi6/Ly8ioV4vHx8dx0Qykfuru7eelLXxqKH43G7zonJibYu3ev7/SL0DhK9U3ZJ6Q8mr62igWy0dFRbrvtNh599FFjO4Uy4dPT03R1dbG4uEg8Hq/az1QqNXno0KGST4GLXcvExARbtmwhk8lw9uxZAJRSf4X9sGO0ascaQLHrnJubY8uWLXz7299m69atjXZR8HD48GGGhoby7o+TJ08yNDTEysoK166JslE5NPX0QrMuGXNy/X8a+BD2E/kPplKpY6ZLcyzL+l3gl4DPAR9ulmwqgHQ6fcGyrI1B58kSpGhQxp4SF0zOEyDWaAeqYWFhYdCZR3oN8Dtaa+UcfwU7GCmTG9c55wFgFkg7Ng5gq+WmTe2YoJT6EewMqf8I/JTW+t9orc+41xL0cs77MPZSnxRwSin1XicbK/JYlvUXzq8dhdcGuI/B/5sE3Gjg7ZfAZ4B7nd9vxr5fBrTWSgKuOU090vVDKfVZ7IBmHIiUUl8Fflhr3escJ4Asdoru10Lw6aeBtwG3AL8C/E0YS6CUUncCv4Gt4fUHwMejnFLsLNLH79qdTDMty8Oij1JKA/9da/2RRvvSTLRk0AU7D7+cXaKcheLamzJaro0StjcBk8BHgF8tlhwRQhkHgWHsEf+7w7YvCIUopZLAonxBlkfLBl1BEIQo0lRzuul0OqOU0qVe6XQ6026+VONj2H6GUS/NULetSiP6TLvRVCNdVUJO3U0hDZJTB0ilUiuWZfl+4QR97lIood7Z2cni4iILCwtcuXKFvXv3NnTBuLuwfWRkhHQ6zeDgYK7OxsbGGBwcZMeOHaEubFdK6ccee8y3fQ4ePBhYXql2VkqRSCRqotAsBN9jiUSC3bt3B0pcyeoTf5ou6GYyGfr7+7l69WpFcuove9nLSKVSDA8Pl/zcxIaJL1EIupOTk3XzUymlr1275isrb1KeEnn6hmFS9855gfeQtE9xmi45wpW3hnyJa8uyGBy0v1hLqbK6m3N0dHTkzrl8+XIuw+aZZ54paWN8fJxYLObrSzabxbKsnNx2o3FlwV0KZcHdOguTb33rW6vKy2azxGIx482DRJ6+cfjVfTqdJpPJ5Pq23z0Uxl4lrUzTBV2/hrYsix07dgD+cureTKegc0xs+Ply7tw5ZmaiIW9W6gvowIEDNUm59auXTMZ8GtDP70wmw65du0L3ud1Rtjrxm6H0gGPNmjU5KXm/e0QoTdNNLwT5m0gkuH79etA5K4uLi1XP6dZrD95KacRmJWFsHlSPDYgEG6XUrcAvAD+DvU/xj5v0maD7TOZ0/Wmq1QupVGpSKUWpV0dHx2RBltP6wt+z2WxHqXMWFhaKZUt5z9kUj8cXg3xJpVKTjaorpdTOZDK5HOSj4+eFsMqNx+PT1dZLGDYEf5RSnUqpNyilvg4cA64De7XWD5vUvXufYeuw/TJwGluu/j8BPdj3kARcP7TWTfcCDmMr6AK8Clu2XAF9dSg7CVzCTjWOe97v8/zeBTyJLZWtGlA/H8GWsnl7kc+8fnYAnwRGgTeHWP4m7BTRHqAP+HXgt8ptH+DTwPsdG68ANPZAoebt3IovYAvwP51+eQw7QzIZ8Der6rrwPefeeyXwCDDt9Km7G329UX013IEKOs5bnJsv4Wnw69iZXvUof6MTpLYEnHcP8FyDgq5VTn1gb7rzVIjlPw6c8Rzvd9psYxk2bnf+5iWe92L1rstmfxUJiL8P7KpheVuB/+UJ7G8NCuzt9mqqOV0ApdRdwE9rrT/oee99wBNa6280zjPBRSn1X4CzWusvO8cdwB8B/0FrXXrC/YaNXuw9JX5BN1snjQBKqT7gHdjztdexg+2f6Tqp/yo7rf512FMOu4A/Bv6f1rrtlzY0XdAVBMEfZxXCNLCIPQX2SWCkkV9cSqnbsHfVewewDLxba/3njfKn0TTVg7RaU6v002ZLjQ0qq94poO2emlpm269gi3k+oLV+q9b6WKP/U9Ban9ZavwfYDnwbWON+1o4p35Ee6QZtoOw+wQ46x/RJaq2WKjXbMqqgsrzlhNRGgUv0TPppWNcfNerZ9vWmla/Nj0gnR1iWNVAqHXf//v0DQFA6YlmbKxeTQXfzzhcXK9+RsZjEu4/keEmGh4dJJBIMDQ2t2kchTAr9daXgC1WWLcsaMKn/gHNiAe2cu/bu7m42b97M8vIyXV1dnD59OreHRCtT2B5nz55FKUV3dzd33HFHo92ripGRERYWFti5c2fu+iYnJ5mZmSlb1bsZiHTQBf/smCtXruTO8cuAOnHiRNnlFZNBd+XBq+kAxSTeXZuu9lkQrhT2mjVrVklhl5PtVYm/Wmt6e3uxrNXbC5ukg05NTa1qw0uXLpFMJoHgdvbKgE9OTrJ161YuXboEwIULF1o+6Ba2RyKRIJvNcvHixVwdNivF7jmtNYODg1y4ENoS8sgQ+aBrkmpokrJryrp164re/OfOnatKgC+RSDAzM0NXV1deYLp06ZJxwIjFYmSzWXp6eujq6spL6TXd08CUmZmZommgxcoxaaM3velNq94zSct28bv2iYmJ0NSao4xf/8lkMmzbtq3R7lVFqXvO3SullYj0nK5SSo+NjeVUY/v7+xkfH6evr4/u7u5cZys858yZMySTSbZv3862bduM54NkTtesLG85lbbR2NgYHR0duTYaHh5maGgo75y5uTkuX77MAw88IHO6LTrv2crX5kekR7qpVGpyaGgo8CGNyTmmnD17Nu/Gv3DhAuvXr2dsbIyhoaFyTOXhylh7bY+OjrJx40a6u7srtnHmzBlSqVToo53CenADqfsvvUtIbbRy6NChkg/Sil377OwsN910E6dPn6a/v7/MK2wuCtvDvfZnn3226SXri7Xt9PQ0165dKzqd1exEeqRbb9Lp9FXLstaUOqeSjTzCkHivp0y8yYqEeubWm8qAt+omK/Vs+3qilPqxZDL5lWw2W3IUm0wmV7LZ7B6t9ZP18q2WyDpdD5ZlLQIf1UWkz7EXd1+vpGM7f/Mm7D0b4o69Pc7xOm0g8e58HgOeBd7h2OgEPgF0mtgo099/AP6P5/p/FRgKs5xy/HF82AJ8xOPTbwD/4h43W9Axxbmufwe8gJ0KrYBXAz/brNeulHoY+Go2m31NsfvN+8pmsx8AnlBKNdU1+iEj3TqhlHoEeJnW+hbn2JV4P6S1PmxoYy0wD9ymtf5BzZy1y1rETsH9TC3LqQal1JuBz2utOxrtS61xdgQb0Frf02hfwkAptQa4X2t9xOBcBfwI8E+NTvQIAwm6giAIdaStphfCSG+NUtpivXyp9zVHqY6jSNTrp5Zp5FG/dhPaaqRbzlKoSm2Y2gmDevlS72uOUh1HkajXTxj3WaW2q7VfDyK9ZKwWnDp1iu7u7rx0XDery5THH388T57aTZFds2YNe/bsIZlMopTy7Rlh7Efg2ij0ZWxsjJ6eHubm5ti3b5/R9Zg8HR8ZGWFpaYnOzk66u7vRWrOwsIBSyricchgZGfGVAbcsK7COoTmf6IN5e/T39xfty1GgsF96JdyrpVjfGBsbY/369bz44osheF9b2m6kW0oe3HSkayIxHiRPDYH7EZSUgXf3I6hW7ty9piBfMpkMAwMDzMzM0NfXV1E5pihlJsFeqn6aWQbctD36+/u5evVq5CTqw7jPStk26RtRbve2G+kWkwdXjhx5GDbKkacuth/B5ORk4H4Ek5M38j1MfDGhmC9XrlzJ+XLy5Mmc5HyhJHctZNxNJNj96ufcuXOh+1NvgvqP2xZQXbvXimL9MpvNEotV/xipVN9ohmSKtgu6fp15aWmpahuWZXHrrbcCtd2PwEQGHsj5YkIxX7z4ldPb21tWOab4BdQzZ85w4MABINw9N6JGUP8x6YONpNiX+OjoaCiy7X59Y2JiItc3okzbTS/U40GaiTz18vJy/Pr16+tLnFNyTjeZTF7MZrMbw3iokEgkLpXyBeonN6+UGgAy1dYxNO+cbljtga3jdz5E14yQB2mlaaslY0Hy0ib7NJhIVAfJwC8sLAwuLi5uCDinpAx8Npu9PSyp8iBf6iWJrpR6BfBkPB5fCCovFoutAB/lRobf+kL/mzHgQvH2wNYZ+w5wOB6PXzZoj6vAU0qpdygnAteLMO4zP1KplMm1T4d5PaGjI6COWc8X8IfAaef3fuzUyrsoQ9YbSGAr1d6JLQ/+fuDTzmd1lQcHXgacxZEmx1Yg/r1a+AEsAYecct4JfDGMcoBebIn288CPFvm8UPK7D1vm/R+AR4Efb3S/qmH7JrDVdS8CP08Rdeli9eP83A18F/h74KY6+/1eYNrTXt/BTl2uuL8AnwOuAjv9rh94I7Y+3Lsa3XZ+r7aaXiiGUuo4tjR4xROBylYofhq4WddZ7VQpNYmtvLu3zuVuAiaBH9ZaP1qlra8BPwps01obr/lRSsWAo8BLtdbrqvEhiiilfgn7C/0J4Be11hMV2Ig7Nt4NnNRavzxcL439eAT4Ca11xWvGlFIfBi5prX8n4Lz/Czyttf7DSsuqJRJ0ldqJvSfC56uwoYAPAL+ptV4OzTmzst8OfEtrfaqe5TplvwdbVnu+Sjsd2H3R/GlmG6CU+gywETtYVXWjKqX+LfAx4IeqtVVh+ZuB12utP1XvsqNG2wddQRCEetKyD9LqJXtuYqdeREnqvVE58lFvsyjtHdDq/SVKde2lZUe6ymBpSSqVyltsX4wgG0NDQ4HCkvXaXByqX9plUm/uE+ha+1IJJv7XqmwTTOu3Hr6F4UsY95nbl8KulyjVtZeWTo44ceIEGzZsyJN1XlhYyMmeZ7PZwFRbP0l2rXVOydcgHbUsGXg/DOTOGR4eJp1O5+Wlz87Okslk2LJli3FZQVLvlfoyNjYGQDweD6NKiuLXZolEgvXr13PbbbfVrGwTCvuld0+JgwcP1tWXQmn3U6dOEY/HicVixntqFKtvt51dQdGA+2wAitdLPB5ncXGx4nrx882yrIbJu7d00L148SLnzp3Lk3VOpVIsLS1x+vRpwD+7ZXraXupXSpLdxc/G+Ph4KGmPXvwykZ5++mmAnEy5V6JdKUVnZ2fgyNOllNT7xMSNB+jFso4ymUwudbiYL729vWQyGXp7e0OtFy9+baaU4sqVK7mA0CgK+2VPTw/pdJrZ2dm6pzAXSru7fduyrMD/4FyK1XcymSSbzeaUmv3ukUzmxn/3xeolm82SSqUqbjM/39x+2AhaOuj6yVYvLy/nRjtBqaR+8tCZTIZdu3YZ2QiToLJ6e3uLBuXr168bj/AOHDjAsWPHitpZXr6xOCMojdnPl1qlDruUarN77rmHzs7Gdnu/fnnhwoW6y6n7+TI5OWm8p4ZffZ8/f97NjDO6R2ZmZoqm9u7duzdnp1z8fJucnMxtGlVv2npOVym1Shp8fHwcpZRXvj3QRjH5cFc9d3JykkOHDoUyb6TUarnzInLzgf6GMacLq2XV3ZH9tm3bQvGlEmROt76+mNrwu0disVgu+MmcbgtQTNp5bm4Oy7LYtGkTyWSSoQBZ9WI2nnvuOe655x6OHz/Otm3bOHToUEkbYaTIunaGSkiZ+/k7NjbGmjVr2LRpk1E5QfVm6kuhbPjc3BxKKS5dusTLXx7+Gn1lr/ct6v+VK1dIp9OMj49z8803h152ORSTt0+lUszNzdV9TrfQlzNnztDT08O1a9eM26hYfY+OjpJKpdiyZQvJZLLkPZJMJi9ks9lNxfrL3NwcS0tLFfcXP9+6urqYm5uryGbVNDolrlavVCqVwU7V9X2lUqlMtTZM7LTaNZtcb1h2TF/YacFfSqVSWcM2WwB669k+QDqZTC5HpT+1en+pdx807gf1LrCuFwevAa4Baed4I2ABu8q0cwvwOs/xF4GvNfr6fHy9z7nG9c5xL7Zke7l2ngJ+23P8R8BjFdj5OWCt8/tWx7fba3DdS8BxIGFw7lrgHDBT57a5HbgM9Pt8/nfAX9XZp78Dvuo5fhi4o0wbdzrtOugcJ7H3SPjJMu18C/gDz/FPuTaruL4Y8CK2XL373i9iS9nXrZ69r5ZNjnC4B3tfggUArfVFYBp7gxtjtNZntNZf9rz1GLA9NC/D5aXARa31NIDWelZr/ScV2BkAvPLYI0DZu2NrrT+ttb7qHL4IzGEHn7A5BOzXWi8a+HQVuw+8pgZ+lCr3lNZ6ndZ6yufz12qt31xPn7D78eMeH76itT5Z4vxi3In9ZTLp2MgCo9g7o5XDIPZeGq4vf6m1rnaJQSewDjjssfv7WuuVKu1WTMs+SBMEQYgirT7SLYuopg1WQy3lsGtdTj3bIyopsY3sg1Hq/7XyJQrXKCNdD1FdYlINQdcU1vXUopx6tkc9l0/V2kalRKn/18qXKFxjyywZC9qXwET2HPylv93UyChJf5tes1d2vquri9OnT2NZFmvWrDG1YyQHX0zeXilFT09PVfU2MjJCKpVi8+bNRVOSw6LQ/0wmg1KK5eVldu/ebWSjmFR9Mpnk8uXLZaXVVmujGKbS7t7+39nZyeLiImNjY0btaHKfBfUnry+FMvNjY2NorYsmS5hcX7Fr9KZi10JktZCWGekqpbSJZHkY0tZRkf42veYgOWwIRw5+aWmJmZkZ+vv7i5ZTbr25o5LJyUnfNglzpFutnL1Stjz42rVruXr1akVS9WHYKGW71v3f9D4z6QvlyswH3Q9Rka9vmZEu+Od3X7lyJXeO394F7l4MxaSt3Vz0m266qWQ5U1NTJBIVb4xfESbXbCKHHSTBHrRHBdzYXKRYWaVslNpv4MiRI0VtKqVCl9v2k7O3LMt4BFRKHnzvXjNxj1pKjFfa/4Hchkl+7Tg5ORlYzjPPPFPSxtTUVG4zpGK+pNNpVlZWcv+lFVLqfnD7sp/d6elpNmzYUGnVGtNSI92gOUUonWqolOLo0aN5jeZ2lhdffJH777+fWCxW0oZrJwrzXu41+11TJpPJbUhiMB9bcTnT09Ps2rWr7HpTSmk/m+Pj4+zZs4d4PB7aSPeRRx5ZVc7o6Ch79+51/60OHKWWqoO77767Khujo6M88MADFV+zSX8pVfb+/ftJJBJGfaGa/hTky+zsLDt37nTvxVX/GVVqt+Aaa3b/tkzQDZKtNpE9h+D87yhJf5tcc9A+pUop4vH4dK3l4E32Li6sN3mQVpkNP8KQdg/q/yb3memcbrn1YDqn2/BBk25QVkatX+QrhBZVIC04503xeHyF4LTB2XLLaeQ1x+PxSwHXsyoNsoK666tFOfVM4wzy36SsKKXVVtJf4vH4bLllV9JXwuhPpvVQxO7VetWvr0+1NN4sL+DT2OnCL/drMOf45dgZVZFMAS5xfR8GPu78vgm4AOwM+0sCeAvwDbfugD/GFuysqBzgCwGP/GIAABWSSURBVMAyEC9sE+zUbI0tdhiW/28Hvu7x/1ngbeX4D8SxU4zvdo4fAs5iPz8px877gc86v68HXnD6X82+2J36/HRhXTu/fxnQteynPj6dAw447fET2JmRlfanB5xrvL9If+oAFoCjNb+meldiFF/Ah4D3GZ77TuATjfa5jGtTTkf7mTqUpfHsHQC8t5ob1Qmst5T4/EFgTcj+/2mVNn6t8Jodu79agS+/Uue+8kqg0+ezOHConv4U8SFVzRetcw2vKPH5TcBdtb6OlpnTFfxRSr0e+Ftd48ZWSr0GOKK1vuYcx4DXaq3/tpblhoVS6seAYe3s1VGhjUHsL4pjnvcOACe11hfKsPMTwN/pBu4REEWcNvoXrXW4S1fqiARdQRCEOtLSey/UOs86Cnnc5VKvvRjC8MXEn1bO0Q/Tl3pJpVdaJ2HYjVI9laKlR7pKKX3s2DHS6TSDg4OrUkh37NhR1fIQ135hSmFY9svFdMnMyZMnc6mVAC+++GJOHXX//v1G/oaROmxZ1sBjjz22Kh0znU4DsGfPHqMlVuW2sWk9+bWti6soXeoaIZyU2GL1FI/H6e/v59ZbbzWup2LXU07bK6W0t//EYjGee+45AJLJpHH/8fPPm+7tpiBrrbnjjjsClxz61ZNXadm0nrzpx64fs7OzJJNJ7rzzzqru6ZYPurVM+VNOymYqlSqZZluvoKsM0yCD0nVN/FUGKaXVpiib+FNJG5jWU5RSYhtRT352wug/xeyWqu+gujbp2yb+1eOebqk04GKUSmsMI+WvVMpm2PLrJpRK0XTTIIPSdU2pNHU4KEVZOam3pu1TSRuYpHIX6ztKKebn53N/V03q+fPPPx/oi5sSW6ye0uk0mUyGzZvN9pb3qyelFLOzs0Y2ILz+U4jfveqmT/vV0+joaK7NSvkWRhp2KpWq6hqhDYKuX4c/f/4827dXL/7g1xEymQz33Xdf1fbLxUTq2mQfBROKSbCb+OKlWPtYlsULL7zALbfcYuRHJW1gUk9+fWdpaSknZ29yjUHnVONLV1dXzpcgSgX3hx56yMhGKTuXLl0ytlEMv2t8+umnger7tjKUcS9VT7t2lSuGsZqWn14Iur5qpxdqab9cwkiDNPXXIAW56tRhE38qaYOw0kWjnBJb5PNQ+mqQnWqmF0rZNUkjh+jUU0lqvRC4ka94PD5PDVP+oqo26n1RkAYZ5HMymbwQRjkm50Ql9baSeipmt5I6qJUvtaqnStK9TV5hpJFHqZ5K9rVq/jjKL+Bz2CmEN/s00gBwGlvZV1VZ1heAdzq/vw0nldDvpmr0C1iDLdC53Tn+LPDBRviMLUY4A3Rhp3pq4M/K9cO5hvc4v78O+B52Nl6lKaMZbKVc5XmvD0hjiy4+Wud6ijl18ybn+BPAR8ttM+CbwJzz+11OP1hTpo11wCy2unYf8HngXdX2HWAP8JzbbsD3sdOoy+0LR4A3OL+/C/hiBfX0euCY8/t2p+5/JIz7o26dpp4vTwd9Y8B5e53zNldR1iHgOtDtHMex5ajf1uh6KOHzX2BnSLnH/wrIAl0N8OUYdoaRe3wnsKVMG7uwJdjdHdViwBXgl6vw61ngHp/Pfg5nj4Y619UruDEleC+wCGwq08YtwA7P8UngL8u08RXgCc/xG7H3LklWeX1jwKc8x78DTJRp463O/Rd3jrud+/NQmXamgfd7jg8AHWG0Y0s+SNN26mTgnIvW+lsm5wXQDXxba33FsXldKTUMJKu0W0uuAF/yHD8KTGB/YdSbKeCf3QOt9bMV2OgGnsbeyAet9YpS6utUkfyjtb6zxGefxt4kqa5orf/Fc3gCO0gV383b38aZgre+CBRfX+XPLHafcfkG9n8G1ZLB/q/R5YvYwa4cUsBhrfV1AK31FaXUt7H7SDlMYn+54Ng5Uubf+9LSD9IEQRCiRtOlAbdD2me7Uq82qFdKbCX+Rtm3diXsumy6kW6tlnREbflXO1KvNqjX8ilTO83iW7sSdl025Zzu8PAw6XR6VY712rVrc/sJVMKJEyfYsGHDKpvz8/McPHgwLPnpukj5uIQhTR+WzybrY/3adsOGDVy9ejWUNnDL2bx58yp570QiweLiovE1HTt2jJtvvrmoXLmpbHshblaVa9crZ++mt5rWZU9Pj++eFGH1Z5NzCvtPGHt3hOSb0Tppb2xw2zmTsQe3+/btC/rzPJoy6M7Pz7OyssLx48fZunUrWmuSySSJRMI3N92Eixcvcu7cOdauXUtvby89PT0opejs7OT06dNks9mgXPsBCMy1D1yUHyaWZQ2Y+FMPnw18Kdq269atY2pqis2bN4fVBszPz/PCCy9gWVauHPd9NxPJhMXFRY4fP57rM1prent7mZ2dzSnslsvs7CzpdDrPrtsX3azBcuoyk8nkXePExATZbDbU/lxu/zHwP2biWwj+lyzHrcvC2ODWZSXt3JRB97WvfW1N7L7yla8MPMckBTIo177emPgTtI9CrX1xO65J24bRBmH1IZM+Uy4PP/yw0XnF2uz8+fO5NqumLqempnLnBLWZny/T09Ml+08Ye3fUeu8Ld0+HMNu5KYPusWPHfCXF77333tDtTk5O5uxu374dpRRdXV309/dz5swZOjo68vZxKDxndHSUvr4+urvLXbUSDib+3H///UxMTNDV1cXS0hJzc3NcvnyZF154oea+KKVy9efXBufPn8/JxYfRBiZtbYKJv5VQyj+XwjYbHx8nFovl2szPxtTUFHfffXfJepqfn8+VE9Rmfr6kUqmS/afY3/T19eX+Znl52bdflvKtsG8XnjM9Pc3ly5dz/hez4e7s5u7XEGY7N2XQLaykqakpbrrpJjKZDOPj4xXbLdbI3o6QTCYZGhry/Xt3DmloaChwnqlepFKpSRN/6uFzkC/gf6MtLy+H1gZ+5RTe9CYUu6Hn5ubYtm2bsY1CDh8+zNDQ0Cq7lmUxMDCQu85KrnFsbCxvRBxWfy63/xj0y5VDhw6V2rvjglJKh+DbytDQUOCcblC/LIemW72QTqenLMsquedfJQ9+TB5M1PshWLtRrzYIq5xa+Btl39qVsOuy6dbpWpYVB45rrVXhC3iHc87W0lZW41TYRuxsm62Ovd3YmVpprbWSDlpbnPrtwc4su91pg5dgZ631htUGjo0O4DHsvQwU9p4K09ipv0blOOe8A3sfBrcPfghbxlxV4u/CwsKgY+e3gE967H4ZO63Z2Dfn7x4F7nV+PwScAhLSn81x6umHsTPm4p5Y889ArOy6DCOXuJ4v7A1SYiU+Lytvv+BvP4VHPpsb8uXvbvR1t8sL+FVvGzjvaeBjIZezz7Hr3QRpFnisTDtXgW94jl/n2PXto4Z2NfBfPcd/UlgvFdjscOy+pdHt3Gwv7DTzjOfY3QTntnJtNd30Qi1RSnVhj6gmPO/djL3phvniTaFilFJp7E1cznre2wFc1I60e0jlKOwb5pTnvT7sUaDxHLZS6iXAuHZy/Z337tBanyzxZyZ27wBOaecGVbac/Uu01j+o0u6twHNapN3LQim1FbiitZ7zvHc7cFqXGUQl6AqCINSRSM3pmuQ4m+Q5S9650G7UShpdCJ9IjXSVj0y0m467tLTEvn37jCQ3ikkxd3Z20tHRwb59+wLlP6KY0ttq1CtFOaxyDM4JTCmtVUqsZVkDhRLm3rTfoaGh3Hnl+NaO1LpfRi7oBskfO+cFBl0Tyeow5LNL+SGURgVIoYfVBmGVY3KOSUppob8qJDn7IAnzMOqyHTBpD6i8LiOXHFFKJnp+ft540XkxyepsNotlWbkF4SaquFFL6W01Sin5uoTRBmG1dZBibam01HJTYr1ptCbprn4S5l4ZepOUXqHy1PlMJhOYOh+5ke7Ro0d9U3x37dpFPB43Gun62XFllGOxGKWu3R0ZBJ0jI4PKCdoyL6w2CKscQ19KuVLUXxP/THx75JFHVvX3c+fOsXv37tzoTPpzMLXul5ELuib+mATdIDshyWfLHFgVGMi4h9IGQXN0yWTy4srKSkcIvlQ0p1sPOXulFPF4fFr6czC17peRCrom6XYQ3DmCKq2YDaVUn9Z6pvB3LybnCJVTzzYIshOWL5X4W4ndeDx+ptwgIP3ZjLDbOVJB10Up9dvYWWBKKbUBOA48rLX+XhkdtwNbuO/HsVN5h7HTfO+SziW0IkqptwOfw848Wwd8Ffgw8E3p89EhqkE3AfRoraec4y8A92utt5f+yzwbHwferrXuc447gfVa6wu18FkQGo2TZTeotT7vHH8UeJfWem1jPRO8RG71AoCTcjvleesTwM+WaeZZ4Hc9NpdwJLoFoRVxHmSc97z1WWBnY7wR/IjkSFcQBKFVaWgacLNJbgtCFJD+3Nw0dKRrsrTLXR6mlEqU2umr1OfllGPityA0kjDvG6H+NHxOd2RkhJ6enlXS5319fVy7di1PJtpdlOwlmUxOrqysxIH1xT4PKieZTOZl7AhCM1BMqn5sbIx4PM6aNWuM7hvLstp+TW4jaHjQnZ2dJZvNrpI+v3bN3jo1m80GZX4MQHB2iF857meC0EwUk6p3Zde7urqM7xuh/jTF9IJfSu/09DS7du0CiqdAjo6O8uCDDwam/LrlyPSC0AxUe99YlsUtt9wi/b1BNHyk6ydtfObMGR566CHAX7nV+29Tsc83btzIkSNHSpZTrVS2IDQCEwl5v/umv7+/ka63PQ0PuoUS1idPnsxtSxeLxUgmkxw6dMj3702kmCFcCWVBaDRBEvIm9039vBW8NGx6QSl1dzKZPJ7NZoM2CJleWFgoKbkehMhRC62E9OfmpiGP7Z10xe9ls9mP6SJS6u4L+HnLstYrpcw20fXBI7n9FPCvHdsdwDngDVrkqIUmwumrSeAM8CqnPyeAS8ArpD9Hm0aOdF8F/LMuoUrqBOdXAf9otOdj6fJuAX4AbNZaZ5z3zgBXtdb3VGNbEOqNUupB4CjQpbW+6rx3Afi+1vpQI30TStNWacBKqaTWOus5jgGdsnhcaEaUUimtteU57sC+p5ca6JYQQFsFXUEQhEYT+pxurfLCJd9cEIRWIPSRrnJk1JeWlujs7KS7uxutNQsLCyiljCTUy7GbTCa5cOECBw4cyNmtl7S3INQD6c+tRU2CbiaTYWBggJmZGfr6+oqdU1HQnZ6eZu3atVy9erWkXWUouR10jmTsCFHAtD+LvHpzUJPkiJMnT+bkoL0S6rOzszn580ooJc9euH+CiWS1ify3IEQBk/4s8urNQU1Gun4536Ojo+zfv59EIlHRSLeUPPt9992XN9IN2gAHRI5aaA6kP7cWNQm6tdhcphy7YUluyxyYEAWkP7cWoU8vpFKpyaBt49yJ/1rZLda5giSSCz9fWFgQ9VQhEkh/bi1CXzJmWdYVbOnzTk8673rn568752wt167T8WLAaeDljr23ASNuGaW+yb2dspgcddDnghAlpD83L7XYe+HTwJu11svuG55G/xDwKcA39TeA/wG8BHjUOf5r4OVKqbdLxxIEoRloqow0pdRBYL/W+jc87/0a8Jda6xON80wQBMGMpgq6giAIzU5Z0wthpeJKSq8gCO1KWSPdsJaDmdhJpVJks9lSn0vqoyAITUfZS8ZKSZl3dpqbGx4eJpFIMDQ0lCchPTg4yI4dO8hms0FpugOunWKfO6mPongqCEKkKDvolpIyn5+fN7YzPz/PmjVrVklIT0xM5Ea4fqmP09PTOTt+qY/PPPNMuZcmCIJQcyqaXiilRHrfffcZTS8YpgqXsgFI6qMgCM1FZOd0lVKMjY3l1E77+/sZHx8nlUqxadMmtm2zZdMKzxkdHSUej7N9+3a2bdsmQVcQhEhR9vTC4cOHGRoaWhUM+/r66O7uNrZz9uzZVcGyq6uLubk5Dh48SDKZLLkjmfsgrZT0eiXpxoIgCLWkrJFuWNLPIiEtCEK7UtY63YWFhUHn3/WjwP/27K3wN8Cfmko/O+e8FpgFEo6NlwP/2bUpAVcQhFak0r0XHgK+4zk+Azxcpo23Ape11tcBtNbf1Fp/skJ/BEEQmgJJAxYEQagjtdhlrGwkLVgQhHYhEiPdWqlNCIIgRI3AJWMG8s8rlmX5jphN9kgAO724v7+f7u7uvPRirTWbN28OclMQBKEpCBzpKqV0kLRzGPLQ09PTpFIprl+/Tk9PTzE/ZKQrCELTY5QcMTU1VXT/g2QyCZjJQxezMT4+TkdHB+Avr15qpzFBEIRmw2ika7C/QcnPIXiPBL+9GMbHx9mzZw/xeFxGuoIgND2BQTeRSFwKkHYuOadrIg8NpYMyyPSCIAitQeD0wuLi4gbvsYm0c7ny0KlU6tlayLYLgiBEjUgsGXNRSn0GeFZr/ZtKqb3AY0AaWCNqv4IgtAKRCbpKqSHgeeClWmvZgVwQhJYkEhlpDueAXwG+32hHBEEQakVkRrqCIAjtQJRGunkE7ccgezEIgtCMNGSka5BaPGlZ1oDonwmC0GqULdcTBpZlDZjIq584cWKV1LtMhwiC0Mw0JOiCf+rw+fPnc+dcvHixqNS7ZVmNclsQBKEqGhZ0H3zwwaLvb926Nfd7IpFgZmaGrq4uLl++nEsNlqArCEKz0rCg66cqHIvdeLbnF5gFQRCalUg+SEsmkxey2eymsbGxVTLta9euZWBggG3btsmDNEEQmo7IrtM1WeEgisGCIDQbkV2n6wTUNcA7PVLvHwBGRaJdEIRmJbIj3WI4m+B8XWvd22hfBEEQKqGpgq4gCEKzE4npBZFgFwShXYjESFck2AVBaBcatk63kJGRETo7O9m+fXte2q9SikQiQTKZRClVMjLLigZBEKJOZEa6JhLspfZrcKXcZTQsCEKUicxI10SC3W+/hsnJyZwcvCAIQpSJzEjXT4L90qVL7Nq1K1Dq3bEjI11BECJNZIJukB+pVCpv1OtzjszpCoIQaSKxZCyVSk0qpQh4TbqZaZ4MtfXe3yXgCoIQdSIx0nVRSv01MKy1/j2l1ADwNPAQMCkS7IIgtAKRCbpKqZcAZ4BbtdZnnPfOAzNa650NdU4QBCEkIrN6ARgFXu8GXIcHgA0N8kcQBCF0IjPSFQRBaAci8SBNEAShXWhI0A3a4CadTmdMzmmE74IgCNXQkOkFpZQOkGAHKJn2u3//fkmEEASh6WjY9EIsFmNqaiq3DndwcJCNGzcSj8cDz1m3bl2j3BYEQaiKho10S5WrlD2ADTpHRrqCIDQbDVky5mSglVIDvriystKhlFpfykZtvBMEQagdkVkyppTqc7POvL+bfi4IgtAMRCboCoIgtAOyTlcQBKGOSNAVBEGoIxJ0BUEQ6ogEXUEQhDoiQVcQBKGOSNAVBEGoIxJ0BUEQ6ogEXUEQhDry/wEvl+kAJZfOhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(clf.fit(x_train,np.squeeze(y_train.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us limit the depth to 5 say"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance are  [0.         0.02792399 0.         0.         0.04119422 0.12667636\n",
      " 0.07787342 0.04024308 0.06023461 0.60176289 0.02409144]\n",
      "train acc is  0.8613138686131386\n",
      "test acc is  0.7389162561576355\n"
     ]
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier(random_state=0,max_depth=5)\n",
    "# print(clf,end='\\n\\n')\n",
    "clf_dt=clf_dt.fit(x_train,np.squeeze(y_train.values))\n",
    "print('Feature Importance are ',clf_dt.feature_importances_)\n",
    "# we got some better features \n",
    "\n",
    "train_preds=clf_dt.predict(x_train)\n",
    "train_acc=accuracy_score(y_train, train_preds)\n",
    "print('train acc is ',train_acc)\n",
    "\n",
    "\n",
    "test_preds=clf_dt.predict(x_test)\n",
    "test_acc=accuracy_score(y_test,test_preds)\n",
    "print('test acc is ',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see Decision tree has some potential of doing better, so that is ok\n",
    "\n",
    "##### Let us do Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 425 candidates, totalling 1275 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1275 out of 1275 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=5,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=0,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(1, 18),\n",
       "                         'min_samples_split': range(10, 500, 20)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(accuracy_score), verbose=2)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "parameters = {'max_depth':range(1,18),'min_samples_split' : range(10,500,20)}\n",
    "clf = GridSearchCV(clf_dt, parameters, cv=3,verbose=2,n_jobs=-1,scoring=make_scorer(accuracy_score))\n",
    "clf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0093085 , 0.00731508, 0.00865213, 0.0099771 , 0.01396553,\n",
       "        0.01163753, 0.00830126, 0.00798051, 0.01163308, 0.01130406,\n",
       "        0.00897662, 0.0083123 , 0.01162283, 0.00731381, 0.01031049,\n",
       "        0.00964133, 0.01496116, 0.00831207, 0.00897646, 0.01030731,\n",
       "        0.00964157, 0.00930826, 0.01030238, 0.01196782, 0.00832256,\n",
       "        0.01163912, 0.00963783, 0.00764823, 0.0103031 , 0.01130327,\n",
       "        0.00997313, 0.00897543, 0.00930675, 0.00930937, 0.00930794,\n",
       "        0.01562945, 0.01130287, 0.01030691, 0.01230152, 0.00964308,\n",
       "        0.00897725, 0.01129476, 0.00830825, 0.00831389, 0.00897662,\n",
       "        0.00997535, 0.0116357 , 0.00864466, 0.00831   , 0.01163562,\n",
       "        0.01030882, 0.01263523, 0.01097155, 0.01163578, 0.0116419 ,\n",
       "        0.00897694, 0.00963918, 0.00930794, 0.00964348, 0.00864712,\n",
       "        0.01030723, 0.0096422 , 0.01031208, 0.00897606, 0.00964554,\n",
       "        0.00897805, 0.01728606, 0.01296798, 0.01063792, 0.00996582,\n",
       "        0.01131686, 0.00997408, 0.012966  , 0.01097194, 0.01097091,\n",
       "        0.01363238, 0.01197124, 0.00897495, 0.0099767 , 0.01096861,\n",
       "        0.01296782, 0.01263046, 0.00997345, 0.01063967, 0.01030723,\n",
       "        0.0099678 , 0.01595839, 0.01097107, 0.01130287, 0.00930961,\n",
       "        0.00931183, 0.00764624, 0.00897932, 0.00930977, 0.01063673,\n",
       "        0.01230017, 0.00930619, 0.00930953, 0.01363047, 0.01396314,\n",
       "        0.00897479, 0.00831334, 0.00930659, 0.01064388, 0.00930953,\n",
       "        0.00964483, 0.0119702 , 0.01097409, 0.00963998, 0.01096288,\n",
       "        0.00864514, 0.00897646, 0.00831119, 0.00930913, 0.00864379,\n",
       "        0.00964276, 0.01030461, 0.00996947, 0.01063832, 0.00764696,\n",
       "        0.00797749, 0.00864474, 0.00963966, 0.01030413, 0.00996518,\n",
       "        0.01031144, 0.01396465, 0.00997464, 0.00898067, 0.01363087,\n",
       "        0.01063402, 0.00997464, 0.0086453 , 0.00897527, 0.01396179,\n",
       "        0.00964133, 0.00864188, 0.00864458, 0.00864919, 0.00864387,\n",
       "        0.0096426 , 0.01097004, 0.00897757, 0.00898576, 0.00831223,\n",
       "        0.00898083, 0.01163061, 0.0119729 , 0.01462873, 0.02161129,\n",
       "        0.01994967, 0.01196893, 0.03257759, 0.03290995, 0.01695418,\n",
       "        0.00731198, 0.01230343, 0.02626046, 0.02127592, 0.0202841 ,\n",
       "        0.0149591 , 0.01496069, 0.01196742, 0.02227227, 0.01263475,\n",
       "        0.00964212, 0.01296894, 0.01662358, 0.00965238, 0.0086449 ,\n",
       "        0.0089709 , 0.00897654, 0.00931001, 0.00930738, 0.00764839,\n",
       "        0.01097218, 0.00995445, 0.01030572, 0.01163236, 0.01030262,\n",
       "        0.00831437, 0.00731428, 0.00798217, 0.00864681, 0.00831199,\n",
       "        0.00731897, 0.00897519, 0.00797979, 0.00665236, 0.00764767,\n",
       "        0.00797725, 0.00864204, 0.0096391 , 0.00897559, 0.0083077 ,\n",
       "        0.00930858, 0.00997305, 0.01097075, 0.00964085, 0.01296528,\n",
       "        0.0109729 , 0.01196623, 0.01196289, 0.01196814, 0.01395877,\n",
       "        0.01230033, 0.01528851, 0.01230073, 0.01130621, 0.01595942,\n",
       "        0.01363055, 0.0132974 , 0.01197473, 0.0089767 , 0.01662691,\n",
       "        0.01063871, 0.01196647, 0.00897368, 0.01030986, 0.00964117,\n",
       "        0.01529376, 0.00931255, 0.00897773, 0.00896184, 0.00932837,\n",
       "        0.01063712, 0.01129977, 0.01294804, 0.0106384 , 0.01163578,\n",
       "        0.00897574, 0.00897805, 0.00964133, 0.01129715, 0.00864013,\n",
       "        0.0083135 , 0.00997297, 0.0086422 , 0.00897892, 0.0083127 ,\n",
       "        0.0096422 , 0.01030628, 0.00897463, 0.01329915, 0.0083135 ,\n",
       "        0.00999395, 0.00997742, 0.00764887, 0.00864291, 0.00930667,\n",
       "        0.01130589, 0.00898043, 0.01065342, 0.010638  , 0.01096853,\n",
       "        0.00930953, 0.01130279, 0.01063553, 0.01063959, 0.01030771,\n",
       "        0.00897741, 0.00863918, 0.01263269, 0.01462523, 0.01064078,\n",
       "        0.01163483, 0.01163721, 0.00864474, 0.00864283, 0.01163594,\n",
       "        0.00997305, 0.0109725 , 0.01197012, 0.00930953, 0.00830976,\n",
       "        0.01329589, 0.00964109, 0.00997297, 0.00897662, 0.00830825,\n",
       "        0.00997663, 0.00897598, 0.01063728, 0.00897789, 0.01063935,\n",
       "        0.00964165, 0.01396163, 0.00930858, 0.0109729 , 0.01096884,\n",
       "        0.00897773, 0.01097043, 0.00831127, 0.00864569, 0.00997607,\n",
       "        0.00831127, 0.0096395 , 0.00964268, 0.01030882, 0.01030596,\n",
       "        0.01130184, 0.0093108 , 0.00864458, 0.00897479, 0.00831119,\n",
       "        0.00864363, 0.00997472, 0.0119671 , 0.01030445, 0.00764569,\n",
       "        0.0079786 , 0.00764918, 0.00731627, 0.00798146, 0.00798035,\n",
       "        0.00798114, 0.00731484, 0.0096372 , 0.00930889, 0.01030461,\n",
       "        0.00964046, 0.01230748, 0.00764211, 0.00665085, 0.00831183,\n",
       "        0.01462658, 0.0079782 , 0.00864506, 0.00963505, 0.01097274,\n",
       "        0.01163594, 0.00930866, 0.01330066, 0.01063967, 0.01063792,\n",
       "        0.01063689, 0.00930715, 0.01196814, 0.0089763 , 0.00798051,\n",
       "        0.00964904, 0.0096422 , 0.01229858, 0.01030906, 0.00930945,\n",
       "        0.00997647, 0.0112958 , 0.00798003, 0.00764815, 0.00765181,\n",
       "        0.0103031 , 0.01163419, 0.009974  , 0.01030405, 0.01097457,\n",
       "        0.00731548, 0.01030429, 0.01097322, 0.01464653, 0.00997162,\n",
       "        0.01130271, 0.0119671 , 0.01263483, 0.01363158, 0.00997384,\n",
       "        0.0099771 , 0.01063752, 0.00764545, 0.00797963, 0.008648  ,\n",
       "        0.00797772, 0.00697883, 0.00765371, 0.00797908, 0.00831302,\n",
       "        0.00798241, 0.00897916, 0.01032551, 0.01296488, 0.01030819,\n",
       "        0.00931096, 0.0089767 , 0.0109721 , 0.01063863, 0.00897598,\n",
       "        0.00964157, 0.0096465 , 0.00930723, 0.00863791, 0.00831191,\n",
       "        0.00930572, 0.00898083, 0.00831111, 0.01030858, 0.01562611,\n",
       "        0.00964197, 0.00997353, 0.00964538, 0.01995079, 0.00698249,\n",
       "        0.00897638, 0.01063553, 0.00831191, 0.00864339, 0.01196655,\n",
       "        0.00931223, 0.0096426 , 0.01063784, 0.02027988, 0.01063919,\n",
       "        0.01363047, 0.0113035 , 0.00964522, 0.00831056, 0.00698113,\n",
       "        0.00731595, 0.00997408, 0.00897264, 0.00930929, 0.0103066 ,\n",
       "        0.00963871, 0.00630411, 0.00631674, 0.00864395, 0.00665053]),\n",
       " 'std_fit_time': array([4.70415519e-04, 4.70753015e-04, 4.57658620e-04, 8.18288154e-04,\n",
       "        4.53076679e-03, 3.08052820e-03, 1.70979125e-03, 2.15311324e-06,\n",
       "        2.48453006e-03, 1.24269448e-03, 1.41130133e-03, 4.70134046e-04,\n",
       "        1.24102729e-03, 4.69291200e-04, 9.39598280e-04, 4.69628375e-04,\n",
       "        4.30866591e-03, 1.24360292e-03, 1.41023355e-03, 2.04483320e-03,\n",
       "        2.48777927e-03, 1.24574990e-03, 4.73367479e-04, 3.25835232e-03,\n",
       "        4.61734347e-04, 2.49234660e-03, 1.25216413e-03, 4.71877812e-04,\n",
       "        2.61959644e-03, 2.85882707e-03, 1.62917612e-03, 4.88741934e-06,\n",
       "        9.38583208e-04, 2.61596107e-03, 4.71316419e-04, 5.89427443e-03,\n",
       "        4.70752210e-04, 4.72327939e-04, 3.39013807e-03, 1.69580967e-03,\n",
       "        8.14200351e-04, 4.76704274e-04, 9.43471378e-04, 9.41227653e-04,\n",
       "        2.44356961e-03, 2.83663564e-06, 9.39256750e-04, 1.24422026e-03,\n",
       "        1.24345933e-03, 3.76214010e-03, 4.67114117e-04, 2.85930744e-03,\n",
       "        8.14880128e-04, 1.24477109e-03, 2.34510730e-03, 1.41057081e-03,\n",
       "        4.70473799e-04, 4.70976993e-04, 2.04497509e-03, 1.24481431e-03,\n",
       "        4.70078667e-04, 1.24574904e-03, 2.04564570e-03, 1.41045836e-03,\n",
       "        2.05061543e-03, 8.15951756e-04, 9.85450988e-03, 3.54845277e-03,\n",
       "        2.35117688e-03, 2.32482227e-05, 3.68873318e-03, 4.30999026e-03,\n",
       "        1.62752179e-03, 1.40944708e-03, 1.62888411e-03, 2.35005297e-03,\n",
       "        1.62743420e-03, 8.14686700e-04, 1.40574156e-03, 2.93298969e-03,\n",
       "        1.41512367e-03, 1.69632674e-03, 8.12933876e-04, 2.48648393e-03,\n",
       "        1.24294479e-03, 8.20533811e-04, 4.95326554e-03, 1.41057076e-03,\n",
       "        4.72272054e-04, 1.88272788e-03, 4.67727360e-04, 4.69628536e-04,\n",
       "        8.15660472e-04, 4.69516145e-04, 1.24252096e-03, 3.38963942e-03,\n",
       "        1.23865613e-03, 9.40717679e-04, 2.35224371e-03, 8.46213192e-03,\n",
       "        8.11282642e-04, 4.79193679e-04, 9.35951265e-04, 3.08973961e-03,\n",
       "        9.36168476e-04, 9.36953152e-04, 2.93725505e-03, 8.17118742e-04,\n",
       "        4.70358991e-04, 8.03222069e-04, 4.67044991e-04, 1.62956559e-03,\n",
       "        4.67886579e-04, 1.24698072e-03, 1.24449499e-03, 4.71321485e-04,\n",
       "        4.71093809e-04, 8.14105855e-04, 4.70078344e-04, 4.70809040e-04,\n",
       "        5.35602266e-06, 4.71147018e-04, 1.69574853e-03, 1.24759796e-03,\n",
       "        1.29903488e-05, 2.05542035e-03, 1.63395738e-03, 8.16828045e-04,\n",
       "        6.12611527e-06, 2.48597606e-03, 2.05258067e-03, 2.15413090e-03,\n",
       "        9.42572527e-04, 1.41495609e-03, 4.53291699e-03, 1.24341197e-03,\n",
       "        4.68288092e-04, 4.68845190e-04, 4.74649032e-04, 4.71033219e-04,\n",
       "        9.40718384e-04, 1.40978407e-03, 2.15416734e-03, 8.17721669e-04,\n",
       "        4.67328311e-04, 8.11869942e-04, 2.34229983e-03, 3.54723441e-03,\n",
       "        6.58007852e-03, 8.15137049e-03, 5.08560699e-03, 1.41146986e-03,\n",
       "        1.32383027e-02, 1.34532596e-02, 6.51427136e-03, 4.67212230e-04,\n",
       "        1.88053764e-03, 1.69607438e-03, 9.15130935e-03, 5.89419391e-03,\n",
       "        6.15008232e-03, 1.40562590e-03, 2.93531133e-03, 1.05980839e-02,\n",
       "        2.05009293e-03, 1.24324181e-03, 2.93714732e-03, 5.77653016e-03,\n",
       "        9.33218338e-04, 1.24345430e-03, 8.07297592e-04, 1.62898151e-03,\n",
       "        9.40887379e-04, 4.66312894e-04, 4.68955157e-04, 8.15659109e-04,\n",
       "        1.37735906e-03, 9.40943167e-04, 9.34198966e-04, 2.04916769e-03,\n",
       "        9.42077943e-04, 4.70471583e-04, 8.11964154e-04, 1.23995170e-03,\n",
       "        1.24324197e-03, 9.42586237e-04, 8.11765565e-04, 1.62771613e-03,\n",
       "        1.24623708e-03, 4.70473194e-04, 8.14398431e-04, 4.69068598e-04,\n",
       "        4.68062179e-04, 8.14977394e-04, 1.24725623e-03, 4.70191945e-04,\n",
       "        5.15042996e-07, 2.15549177e-03, 4.70808436e-04, 4.07235628e-03,\n",
       "        1.41152740e-03, 1.63073360e-03, 1.62528279e-03, 1.41006498e-03,\n",
       "        8.15470134e-04, 1.69541983e-03, 1.24461526e-03, 9.39200418e-04,\n",
       "        2.85637949e-03, 7.77115436e-03, 1.69504566e-03, 1.69532660e-03,\n",
       "        4.95048568e-03, 8.13328376e-04, 8.15783964e-03, 1.69585613e-03,\n",
       "        3.25806120e-03, 8.15464256e-04, 9.43369953e-04, 9.39537552e-04,\n",
       "        4.77100170e-03, 4.67909540e-04, 1.40910980e-03, 2.49268750e-05,\n",
       "        4.60923526e-04, 2.48824683e-03, 2.48474327e-03, 1.38848612e-03,\n",
       "        9.40437813e-04, 9.40381209e-04, 1.40955937e-03, 1.41068312e-03,\n",
       "        1.24443177e-03, 1.24372575e-03, 9.38472270e-04, 4.69123976e-04,\n",
       "        8.13906843e-04, 4.70527427e-04, 1.40664796e-03, 9.41223426e-04,\n",
       "        4.69235923e-04, 9.40324334e-04, 8.17710902e-04, 2.61785801e-03,\n",
       "        4.69297418e-04, 1.42165988e-03, 1.40765267e-03, 4.71332741e-04,\n",
       "        4.74746093e-04, 1.24432583e-03, 1.69472385e-03, 8.06902461e-04,\n",
       "        1.25405423e-03, 4.69853319e-04, 1.41113478e-03, 1.24260465e-03,\n",
       "        2.04984759e-03, 1.24309460e-03, 9.39258202e-04, 4.68902628e-04,\n",
       "        1.62830019e-03, 1.69012111e-03, 3.29411307e-03, 5.23652434e-03,\n",
       "        1.24048107e-03, 4.74748847e-04, 2.85933498e-03, 4.71655762e-04,\n",
       "        9.41448249e-04, 1.87666746e-03, 1.62937082e-03, 2.15564173e-03,\n",
       "        2.44610138e-03, 2.04881563e-03, 1.24402800e-03, 4.71380644e-04,\n",
       "        1.24322079e-03, 1.62752358e-03, 4.89903609e-07, 4.70488982e-04,\n",
       "        2.43938472e-03, 5.84003864e-07, 1.69618442e-03, 8.15367582e-04,\n",
       "        4.69628778e-04, 1.69529681e-03, 6.46515089e-03, 2.61933235e-03,\n",
       "        1.62615995e-03, 1.63024690e-03, 8.12641705e-04, 4.95352164e-03,\n",
       "        9.40904980e-04, 1.24322059e-03, 8.12837678e-04, 9.40211902e-04,\n",
       "        4.75923895e-04, 4.67062030e-04, 9.41790213e-04, 1.24398522e-03,\n",
       "        1.24666953e-03, 2.85824578e-03, 9.39874969e-04, 8.13322784e-04,\n",
       "        4.69740766e-04, 9.39032108e-04, 8.15367164e-04, 3.55157817e-03,\n",
       "        1.69800709e-03, 9.40157333e-04, 1.40995269e-03, 9.39874969e-04,\n",
       "        1.24600305e-03, 1.40927871e-03, 1.41090911e-03, 8.14107469e-04,\n",
       "        1.24198952e-03, 1.69653579e-03, 4.71988999e-04, 4.71768152e-04,\n",
       "        2.35128873e-03, 3.39313240e-03, 1.24256606e-03, 4.70977798e-04,\n",
       "        1.69495223e-03, 3.39080834e-03, 1.94667955e-07, 4.69853319e-04,\n",
       "        2.04187652e-03, 2.36823788e-06, 1.69467164e-03, 1.24302942e-03,\n",
       "        6.16401915e-03, 9.40717981e-04, 9.39256649e-04, 2.48933017e-03,\n",
       "        1.23941867e-03, 2.15350563e-03, 1.62820278e-03, 8.14588756e-04,\n",
       "        4.75925806e-04, 2.34954683e-03, 1.69398809e-03, 1.87784460e-03,\n",
       "        1.24268973e-03, 1.62392163e-03, 2.87294837e-03, 8.13517507e-04,\n",
       "        9.38414040e-04, 9.41394907e-04, 1.69126203e-03, 4.71258324e-04,\n",
       "        8.13809542e-04, 9.39596183e-04, 2.15082303e-03, 4.71988518e-04,\n",
       "        1.24366670e-03, 1.41360533e-03, 4.93227555e-03, 8.12738711e-04,\n",
       "        4.69515903e-04, 1.62558588e-03, 3.76264585e-03, 3.39096436e-03,\n",
       "        2.15332130e-03, 8.11572454e-04, 1.69389232e-03, 9.38132834e-04,\n",
       "        8.13614734e-04, 4.63334365e-04, 1.40973123e-03, 2.14429499e-06,\n",
       "        9.35828629e-04, 8.13031414e-04, 1.24360425e-03, 1.41231285e-03,\n",
       "        1.62645086e-03, 4.56468848e-04, 2.15464561e-03, 1.69872489e-03,\n",
       "        1.24196906e-03, 8.13031569e-04, 1.62722990e-03, 1.69434430e-03,\n",
       "        8.15756081e-04, 9.38582299e-04, 9.33783490e-04, 4.71318590e-04,\n",
       "        9.42617475e-04, 1.24422005e-03, 1.24642957e-03, 1.40860522e-03,\n",
       "        4.71992131e-04, 2.61475238e-03, 8.70669491e-03, 3.76163437e-03,\n",
       "        8.13906998e-04, 4.71342389e-04, 1.55979560e-02, 8.13131154e-04,\n",
       "        1.41012173e-03, 9.35885002e-04, 1.24351795e-03, 1.24400648e-03,\n",
       "        1.62742420e-03, 1.24787343e-03, 4.69010171e-04, 4.70078102e-04,\n",
       "        1.66950978e-02, 1.24292324e-03, 3.29044889e-03, 1.69481188e-03,\n",
       "        1.24279814e-03, 4.67663416e-04, 8.15074796e-04, 1.24067543e-03,\n",
       "        1.62907913e-03, 1.62392232e-03, 1.24719247e-03, 9.41055156e-04,\n",
       "        1.24653444e-03, 9.30113023e-04, 1.69602759e-03, 1.24415524e-03,\n",
       "        4.68392796e-04]),\n",
       " 'mean_score_time': array([0.00199533, 0.0026602 , 0.00231743, 0.00332133, 0.00365663,\n",
       "        0.00365909, 0.0029904 , 0.00233261, 0.00399017, 0.00232641,\n",
       "        0.00299303, 0.00232999, 0.00299398, 0.00299017, 0.00265956,\n",
       "        0.00266035, 0.00432332, 0.00232816, 0.00365615, 0.0063138 ,\n",
       "        0.00299096, 0.00199405, 0.00299247, 0.00266329, 0.00231695,\n",
       "        0.00365369, 0.00398874, 0.00299033, 0.00300344, 0.00232792,\n",
       "        0.00265956, 0.00299191, 0.00332348, 0.00232633, 0.00332483,\n",
       "        0.00232466, 0.00299279, 0.00365671, 0.00432436, 0.00365583,\n",
       "        0.00432356, 0.00232681, 0.00300876, 0.00298961, 0.00266115,\n",
       "        0.00265765, 0.0026652 , 0.00299072, 0.00432269, 0.00398962,\n",
       "        0.00298961, 0.00365901, 0.00199437, 0.00465401, 0.00365861,\n",
       "        0.00365631, 0.00299215, 0.00299207, 0.0043269 , 0.00398787,\n",
       "        0.00299446, 0.00332363, 0.00266171, 0.00332522, 0.00265606,\n",
       "        0.00298985, 0.00299001, 0.00565012, 0.0049874 , 0.00398302,\n",
       "        0.00331235, 0.00664814, 0.00598415, 0.00366243, 0.00299263,\n",
       "        0.00299382, 0.0029885 , 0.00332888, 0.00365194, 0.00532023,\n",
       "        0.00431879, 0.00299279, 0.00199509, 0.00398874, 0.00631603,\n",
       "        0.00398946, 0.00332491, 0.00232927, 0.00532015, 0.00298985,\n",
       "        0.00332427, 0.00299319, 0.00298969, 0.00232665, 0.00332419,\n",
       "        0.00299215, 0.00299152, 0.00232784, 0.00332451, 0.0039893 ,\n",
       "        0.00266163, 0.00398866, 0.00398779, 0.00299033, 0.00232355,\n",
       "        0.00299048, 0.00332395, 0.00265773, 0.00365718, 0.00232784,\n",
       "        0.00265972, 0.00365678, 0.00199421, 0.00299303, 0.00365949,\n",
       "        0.00232553, 0.00299215, 0.00266496, 0.00266512, 0.00398962,\n",
       "        0.00332355, 0.00365663, 0.00299231, 0.00365901, 0.00332348,\n",
       "        0.00398906, 0.00299406, 0.00399462, 0.00299398, 0.00365535,\n",
       "        0.00365774, 0.00332292, 0.00232593, 0.00266099, 0.00299191,\n",
       "        0.00365694, 0.00366298, 0.00332316, 0.002654  , 0.00365766,\n",
       "        0.0023276 , 0.00266782, 0.00398882, 0.00364852, 0.0026625 ,\n",
       "        0.00365408, 0.00199326, 0.00331998, 0.00531848, 0.0083096 ,\n",
       "        0.00431959, 0.00598359, 0.01163546, 0.00631817, 0.00531983,\n",
       "        0.00266035, 0.00531562, 0.00731277, 0.00664846, 0.00864005,\n",
       "        0.00499352, 0.00465298, 0.00266973, 0.00698447, 0.002328  ,\n",
       "        0.0026648 , 0.00334517, 0.00565187, 0.00331759, 0.00299923,\n",
       "        0.00365806, 0.00365663, 0.00332355, 0.00399089, 0.00265924,\n",
       "        0.00299295, 0.00332324, 0.00266433, 0.00299247, 0.00232673,\n",
       "        0.00431887, 0.00365647, 0.0029885 , 0.00431911, 0.00232752,\n",
       "        0.00298818, 0.00399423, 0.00366195, 0.00266123, 0.00266258,\n",
       "        0.00232728, 0.00199556, 0.00598375, 0.00498788, 0.00365806,\n",
       "        0.00332483, 0.00399121, 0.00365647, 0.00332483, 0.00332499,\n",
       "        0.0029904 , 0.00399081, 0.00366251, 0.00365639, 0.00332634,\n",
       "        0.00365822, 0.00366052, 0.00366386, 0.00365432, 0.00498287,\n",
       "        0.00432181, 0.00664894, 0.00365265, 0.00266679, 0.00398413,\n",
       "        0.00432316, 0.00399009, 0.00332578, 0.00298786, 0.0026621 ,\n",
       "        0.00565068, 0.00265519, 0.00265845, 0.00299056, 0.0059646 ,\n",
       "        0.00332546, 0.00299239, 0.00265956, 0.00266004, 0.00233078,\n",
       "        0.00398946, 0.00299374, 0.00299207, 0.00299136, 0.00265948,\n",
       "        0.00299128, 0.00299311, 0.00299382, 0.00332554, 0.00232673,\n",
       "        0.00498978, 0.00398596, 0.00232824, 0.00365901, 0.00332427,\n",
       "        0.00230702, 0.00265495, 0.00265567, 0.00299048, 0.00266353,\n",
       "        0.00332165, 0.00332141, 0.00264454, 0.00366092, 0.00232704,\n",
       "        0.00332379, 0.00797788, 0.0029908 , 0.00399351, 0.00332316,\n",
       "        0.00365504, 0.0029939 , 0.00265718, 0.00266131, 0.00232665,\n",
       "        0.00232927, 0.00398644, 0.00299374, 0.00266202, 0.00265805,\n",
       "        0.00299637, 0.00332522, 0.00431887, 0.00299303, 0.00299279,\n",
       "        0.00399256, 0.00299191, 0.00332761, 0.0026594 , 0.00299104,\n",
       "        0.00265471, 0.00299184, 0.00332554, 0.0039885 , 0.00365861,\n",
       "        0.00299684, 0.00465496, 0.00299247, 0.00265821, 0.00232832,\n",
       "        0.0046494 , 0.00299446, 0.00498724, 0.00299573, 0.00365464,\n",
       "        0.00299255, 0.00265781, 0.0033222 , 0.00232569, 0.00299748,\n",
       "        0.00265702, 0.00398779, 0.00299255, 0.00433977, 0.00332801,\n",
       "        0.00332435, 0.00265876, 0.00232649, 0.00199731, 0.00299795,\n",
       "        0.00199572, 0.00399025, 0.00631356, 0.00298969, 0.0036606 ,\n",
       "        0.00266067, 0.00298826, 0.00299557, 0.00266131, 0.00266329,\n",
       "        0.00266322, 0.00331839, 0.00365742, 0.00266417, 0.00398906,\n",
       "        0.00365742, 0.00232768, 0.0029935 , 0.00365678, 0.00265869,\n",
       "        0.00332403, 0.00332467, 0.00431999, 0.00266178, 0.0029935 ,\n",
       "        0.00332546, 0.00232808, 0.00299279, 0.00232697, 0.00299048,\n",
       "        0.00299017, 0.00332387, 0.00299605, 0.00265559, 0.00332705,\n",
       "        0.0049843 , 0.00332355, 0.00265916, 0.00431983, 0.00331958,\n",
       "        0.00299255, 0.00432309, 0.00398811, 0.00265908, 0.00431697,\n",
       "        0.00265988, 0.00232776, 0.0026602 , 0.00297364, 0.00266027,\n",
       "        0.00299255, 0.0039893 , 0.00299096, 0.00298993, 0.00432189,\n",
       "        0.00234699, 0.00265972, 0.00299096, 0.00399192, 0.00332181,\n",
       "        0.00365909, 0.00232784, 0.00298723, 0.00431991, 0.00299001,\n",
       "        0.00232768, 0.00265678, 0.00263921, 0.00332689, 0.00332173,\n",
       "        0.00298977, 0.00365639, 0.00332499, 0.00299486, 0.00299223,\n",
       "        0.00299486, 0.00298723, 0.00334104, 0.00199429, 0.0023253 ,\n",
       "        0.00232975, 0.00299025, 0.00332514, 0.0029885 , 0.00432634,\n",
       "        0.00266147, 0.00332483, 0.00431911, 0.00399915, 0.00232546,\n",
       "        0.00367339, 0.0039928 , 0.00399502, 0.00266051, 0.0026687 ,\n",
       "        0.00265535, 0.00299128, 0.00299867, 0.00365178, 0.00365631,\n",
       "        0.00366378, 0.00332411, 0.00332133, 0.00365376, 0.00166368,\n",
       "        0.00232577, 0.00265964, 0.00232689, 0.00299764, 0.00232832,\n",
       "        0.00266012, 0.00299025, 0.00232824, 0.00232665, 0.002328  ]),\n",
       " 'std_score_time': array([7.01885292e-07, 4.68786802e-04, 4.80181529e-04, 1.87626531e-03,\n",
       "        1.69478243e-03, 4.68587899e-04, 8.13906749e-04, 1.24461292e-03,\n",
       "        2.15471947e-03, 4.70418660e-04, 8.13128171e-04, 4.67563669e-04,\n",
       "        3.44035797e-06, 2.57030513e-06, 4.73056228e-04, 4.69910271e-04,\n",
       "        4.69631925e-04, 4.70527668e-04, 9.39874767e-04, 3.29369255e-03,\n",
       "        8.15366885e-04, 1.83992972e-06, 1.48680106e-06, 9.43471258e-04,\n",
       "        4.78496406e-04, 2.34611871e-03, 1.41360546e-03, 2.25624554e-06,\n",
       "        8.27380610e-04, 4.71203465e-04, 4.70022017e-04, 8.14004070e-04,\n",
       "        1.24364545e-03, 4.68616770e-04, 1.24468633e-03, 4.67942501e-04,\n",
       "        8.15561491e-04, 9.37628350e-04, 1.88368316e-03, 9.40269382e-04,\n",
       "        9.42300873e-04, 4.69291119e-04, 8.34916137e-04, 8.15188100e-04,\n",
       "        4.70812420e-04, 9.37009060e-04, 4.73539446e-04, 8.12448126e-04,\n",
       "        9.40666302e-04, 8.15367055e-04, 4.82499098e-06, 9.41561003e-04,\n",
       "        1.16800773e-06, 1.69605896e-03, 1.68776171e-03, 1.24417653e-03,\n",
       "        8.14588492e-04, 2.24783192e-07, 2.05161015e-03, 1.62985747e-03,\n",
       "        8.18777151e-04, 1.24545168e-03, 9.54209734e-04, 9.39874848e-04,\n",
       "        4.67746075e-04, 8.15659109e-04, 1.41343737e-03, 2.86358480e-03,\n",
       "        8.15172062e-04, 1.41782064e-03, 1.24824321e-03, 1.24326316e-03,\n",
       "        3.55028288e-03, 4.61817437e-04, 8.14296054e-04, 8.14494142e-04,\n",
       "        8.08465586e-04, 9.43486441e-04, 9.45388048e-04, 2.61552665e-03,\n",
       "        1.69242885e-03, 1.41012124e-03, 1.36267568e-06, 2.06017199e-06,\n",
       "        3.39144765e-03, 8.13809542e-04, 4.70248412e-04, 4.70419466e-04,\n",
       "        3.29093861e-03, 8.16145402e-04, 1.24324538e-03, 8.12349569e-04,\n",
       "        8.15757274e-04, 4.69403753e-04, 4.70752693e-04, 8.13907347e-04,\n",
       "        1.07214749e-06, 4.69574065e-04, 1.87924368e-03, 1.57348234e-06,\n",
       "        4.72837215e-04, 8.12886396e-04, 2.15597017e-03, 1.02239293e-05,\n",
       "        4.67043531e-04, 8.19552089e-04, 1.24581533e-03, 4.72778866e-04,\n",
       "        9.40830554e-04, 4.70752210e-04, 4.69648709e-04, 9.41279697e-04,\n",
       "        2.23938669e-06, 8.12840336e-04, 1.69286366e-03, 4.71205395e-04,\n",
       "        8.14685669e-04, 9.47517475e-04, 4.74203080e-04, 1.41180712e-03,\n",
       "        9.43753517e-04, 1.24356308e-03, 1.29616312e-06, 4.71896444e-04,\n",
       "        1.24383687e-03, 8.19890361e-04, 8.17101829e-04, 2.14844584e-03,\n",
       "        1.23768614e-05, 1.69556469e-03, 4.69797234e-04, 1.24366920e-03,\n",
       "        4.71261983e-04, 9.44428207e-04, 8.13712330e-04, 4.70415116e-04,\n",
       "        4.75901852e-04, 4.70640624e-04, 4.65258950e-04, 4.70752452e-04,\n",
       "        4.73450089e-04, 4.75698635e-04, 1.62869005e-03, 9.45784977e-04,\n",
       "        9.45890096e-04, 4.69945552e-04, 2.25624554e-06, 4.74116711e-04,\n",
       "        2.05077553e-03, 4.98437373e-03, 1.88284154e-03, 3.73284775e-03,\n",
       "        1.24194695e-03, 3.29243209e-03, 2.61624313e-03, 4.71091637e-04,\n",
       "        2.61747513e-03, 3.67273489e-03, 2.48822530e-03, 6.63418159e-03,\n",
       "        1.40596445e-03, 3.08512209e-03, 4.78928681e-04, 1.62898232e-03,\n",
       "        4.67102759e-04, 4.74914290e-04, 4.55897236e-04, 3.75719542e-03,\n",
       "        4.83342264e-04, 4.69361085e-06, 4.67493097e-04, 4.70527910e-04,\n",
       "        1.24407299e-03, 2.15409376e-03, 4.68786358e-04, 4.41485863e-06,\n",
       "        4.69237498e-04, 4.66313748e-04, 1.40984052e-03, 4.71877812e-04,\n",
       "        4.72963226e-04, 9.39818707e-04, 8.15663965e-04, 1.24410285e-03,\n",
       "        4.68955157e-04, 7.28467497e-06, 8.14500772e-04, 4.70428810e-04,\n",
       "        4.72224215e-04, 4.71995824e-04, 4.69459697e-04, 3.89335909e-07,\n",
       "        4.95302553e-03, 1.41034603e-03, 4.70024235e-04, 9.39931240e-04,\n",
       "        1.40899781e-03, 1.24377289e-03, 1.88104207e-03, 1.87974945e-03,\n",
       "        8.12642078e-04, 8.14199048e-04, 9.37591388e-04, 4.69347668e-04,\n",
       "        1.24313859e-03, 9.38585630e-04, 1.24007888e-03, 4.73791182e-04,\n",
       "        1.24263174e-03, 1.63306957e-03, 2.61709105e-03, 2.85979708e-03,\n",
       "        1.23876513e-03, 4.77596883e-04, 2.15475834e-03, 9.40157333e-04,\n",
       "        2.15479275e-03, 4.72325692e-04, 8.10503974e-04, 4.73352428e-04,\n",
       "        2.61847385e-03, 4.67631583e-04, 4.68897900e-04, 8.16340116e-04,\n",
       "        8.17738569e-04, 1.24394273e-03, 8.15075005e-04, 4.70865809e-04,\n",
       "        4.70358829e-04, 4.68696242e-04, 1.62917625e-03, 8.10889928e-04,\n",
       "        8.13906912e-04, 1.41012116e-03, 4.68955642e-04, 8.12934156e-04,\n",
       "        2.02304873e-06, 1.66324373e-06, 4.70768310e-04, 4.69688514e-04,\n",
       "        1.41136488e-03, 8.18679325e-04, 4.73506794e-04, 9.38706237e-04,\n",
       "        4.74074507e-04, 4.44511490e-04, 9.42298400e-04, 4.66598188e-04,\n",
       "        8.11473807e-04, 4.72670163e-04, 1.24401415e-03, 4.72452629e-04,\n",
       "        4.59883710e-04, 1.24694016e-03, 4.69628536e-04, 4.69517113e-04,\n",
       "        7.76691996e-03, 1.74478677e-06, 8.06708514e-04, 4.72328581e-04,\n",
       "        1.69362779e-03, 2.15311324e-06, 4.68181045e-04, 4.66543363e-04,\n",
       "        4.72790488e-04, 4.65031322e-04, 1.41220267e-03, 3.11671441e-06,\n",
       "        4.69746010e-04, 4.68298288e-04, 8.10794025e-04, 4.71047700e-04,\n",
       "        1.24364903e-03, 8.15561398e-04, 8.15074850e-04, 1.62450632e-03,\n",
       "        8.13614734e-04, 9.41573681e-04, 4.70246438e-04, 9.60274217e-07,\n",
       "        9.44161903e-04, 1.12391596e-07, 4.72496235e-04, 8.13420206e-04,\n",
       "        4.72438565e-04, 8.18680344e-04, 2.48773686e-03, 8.14977952e-04,\n",
       "        4.67726144e-04, 4.69909424e-04, 1.24770237e-03, 8.13134579e-04,\n",
       "        8.19557707e-04, 8.80105858e-06, 1.24213737e-03, 8.14880182e-04,\n",
       "        4.71485317e-04, 4.65433303e-04, 4.71433875e-04, 8.21813598e-04,\n",
       "        4.69078697e-04, 1.41074158e-03, 8.14880089e-04, 1.23914613e-03,\n",
       "        9.39317005e-04, 1.24366762e-03, 4.69122683e-04, 4.70864843e-04,\n",
       "        2.78268518e-06, 8.18481464e-04, 4.89903609e-07, 8.14881368e-04,\n",
       "        1.88143654e-03, 1.70079347e-06, 4.74193090e-04, 4.75209252e-04,\n",
       "        8.13424337e-04, 3.42932526e-06, 4.70425991e-04, 9.45325734e-04,\n",
       "        4.71932352e-04, 1.23959113e-03, 1.24377330e-03, 4.75311873e-04,\n",
       "        1.40910964e-03, 1.24383669e-03, 4.70022017e-04, 2.08152149e-06,\n",
       "        1.24404902e-03, 4.69576971e-04, 4.69684641e-04, 1.24434629e-03,\n",
       "        2.61904904e-03, 9.43359107e-04, 8.16049374e-04, 4.69684520e-04,\n",
       "        4.67576434e-04, 8.14977720e-04, 4.70358870e-04, 8.14977828e-04,\n",
       "        8.15595642e-04, 4.67605489e-04, 8.09339281e-04, 4.67053024e-04,\n",
       "        4.74296530e-04, 2.15155550e-03, 4.71208049e-04, 4.69235560e-04,\n",
       "        1.24211631e-03, 4.73000042e-04, 8.13906749e-04, 1.24341176e-03,\n",
       "        8.15853406e-04, 4.69859368e-04, 1.88284897e-03, 4.70091646e-04,\n",
       "        4.70976993e-04, 4.64242069e-04, 7.90952605e-04, 9.41392028e-04,\n",
       "        2.44951805e-06, 8.11863267e-04, 8.15464689e-04, 8.15950827e-04,\n",
       "        2.05108463e-03, 5.03573942e-04, 4.69628536e-04, 8.15366746e-04,\n",
       "        8.14102162e-04, 4.73654190e-04, 4.72272054e-04, 4.70415519e-04,\n",
       "        8.15377048e-04, 4.67324297e-04, 8.14880128e-04, 9.42741692e-04,\n",
       "        4.69920916e-04, 4.99637608e-04, 4.68008970e-04, 4.72837215e-04,\n",
       "        8.12060330e-04, 9.40212023e-04, 1.24349698e-03, 8.16827511e-04,\n",
       "        4.89903609e-07, 8.13614765e-04, 1.10160966e-05, 4.59239172e-04,\n",
       "        2.30608275e-06, 4.68673602e-04, 4.71932673e-04, 3.56832255e-06,\n",
       "        4.69573097e-04, 8.09238816e-04, 1.87823236e-03, 9.44595174e-04,\n",
       "        4.69797033e-04, 1.24791501e-03, 2.15003164e-03, 4.71261219e-04,\n",
       "        4.45465378e-04, 1.41259941e-03, 1.41759553e-03, 4.69853319e-04,\n",
       "        4.67587983e-04, 4.66726655e-04, 1.32507737e-06, 8.13131806e-04,\n",
       "        9.43828348e-04, 9.39425564e-04, 9.36867093e-04, 9.41280603e-04,\n",
       "        1.24128785e-03, 4.72721618e-04, 4.72216190e-04, 4.72562745e-04,\n",
       "        4.69572451e-04, 4.70077860e-04, 1.06695089e-05, 4.69742945e-04,\n",
       "        9.41167225e-04, 8.16534892e-04, 1.24398522e-03, 9.39987118e-04,\n",
       "        4.70643442e-04]),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "                    12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13,\n",
       "                    13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "                    13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14,\n",
       "                    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "                    14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230,\n",
       "                    250, 270, 290, 310, 330, 350, 370, 390, 410, 430, 450,\n",
       "                    470, 490, 10, 30, 50, 70, 90, 110, 130, 150, 170, 190,\n",
       "                    210, 230, 250, 270, 290, 310, 330, 350, 370, 390, 410,\n",
       "                    430, 450, 470, 490, 10, 30, 50, 70, 90, 110, 130, 150,\n",
       "                    170, 190, 210, 230, 250, 270, 290, 310, 330, 350, 370,\n",
       "                    390, 410, 430, 450, 470, 490, 10, 30, 50, 70, 90, 110,\n",
       "                    130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330,\n",
       "                    350, 370, 390, 410, 430, 450, 470, 490, 10, 30, 50, 70,\n",
       "                    90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290,\n",
       "                    310, 330, 350, 370, 390, 410, 430, 450, 470, 490, 10,\n",
       "                    30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250,\n",
       "                    270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470,\n",
       "                    490, 10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210,\n",
       "                    230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430,\n",
       "                    450, 470, 490, 10, 30, 50, 70, 90, 110, 130, 150, 170,\n",
       "                    190, 210, 230, 250, 270, 290, 310, 330, 350, 370, 390,\n",
       "                    410, 430, 450, 470, 490, 10, 30, 50, 70, 90, 110, 130,\n",
       "                    150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350,\n",
       "                    370, 390, 410, 430, 450, 470, 490, 10, 30, 50, 70, 90,\n",
       "                    110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310,\n",
       "                    330, 350, 370, 390, 410, 430, 450, 470, 490, 10, 30,\n",
       "                    50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250,\n",
       "                    270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470,\n",
       "                    490, 10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210,\n",
       "                    230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430,\n",
       "                    450, 470, 490, 10, 30, 50, 70, 90, 110, 130, 150, 170,\n",
       "                    190, 210, 230, 250, 270, 290, 310, 330, 350, 370, 390,\n",
       "                    410, 430, 450, 470, 490, 10, 30, 50, 70, 90, 110, 130,\n",
       "                    150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350,\n",
       "                    370, 390, 410, 430, 450, 470, 490, 10, 30, 50, 70, 90,\n",
       "                    110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310,\n",
       "                    330, 350, 370, 390, 410, 430, 450, 470, 490, 10, 30,\n",
       "                    50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250,\n",
       "                    270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470,\n",
       "                    490, 10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210,\n",
       "                    230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430,\n",
       "                    450, 470, 490],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 1, 'min_samples_split': 10},\n",
       "  {'max_depth': 1, 'min_samples_split': 30},\n",
       "  {'max_depth': 1, 'min_samples_split': 50},\n",
       "  {'max_depth': 1, 'min_samples_split': 70},\n",
       "  {'max_depth': 1, 'min_samples_split': 90},\n",
       "  {'max_depth': 1, 'min_samples_split': 110},\n",
       "  {'max_depth': 1, 'min_samples_split': 130},\n",
       "  {'max_depth': 1, 'min_samples_split': 150},\n",
       "  {'max_depth': 1, 'min_samples_split': 170},\n",
       "  {'max_depth': 1, 'min_samples_split': 190},\n",
       "  {'max_depth': 1, 'min_samples_split': 210},\n",
       "  {'max_depth': 1, 'min_samples_split': 230},\n",
       "  {'max_depth': 1, 'min_samples_split': 250},\n",
       "  {'max_depth': 1, 'min_samples_split': 270},\n",
       "  {'max_depth': 1, 'min_samples_split': 290},\n",
       "  {'max_depth': 1, 'min_samples_split': 310},\n",
       "  {'max_depth': 1, 'min_samples_split': 330},\n",
       "  {'max_depth': 1, 'min_samples_split': 350},\n",
       "  {'max_depth': 1, 'min_samples_split': 370},\n",
       "  {'max_depth': 1, 'min_samples_split': 390},\n",
       "  {'max_depth': 1, 'min_samples_split': 410},\n",
       "  {'max_depth': 1, 'min_samples_split': 430},\n",
       "  {'max_depth': 1, 'min_samples_split': 450},\n",
       "  {'max_depth': 1, 'min_samples_split': 470},\n",
       "  {'max_depth': 1, 'min_samples_split': 490},\n",
       "  {'max_depth': 2, 'min_samples_split': 10},\n",
       "  {'max_depth': 2, 'min_samples_split': 30},\n",
       "  {'max_depth': 2, 'min_samples_split': 50},\n",
       "  {'max_depth': 2, 'min_samples_split': 70},\n",
       "  {'max_depth': 2, 'min_samples_split': 90},\n",
       "  {'max_depth': 2, 'min_samples_split': 110},\n",
       "  {'max_depth': 2, 'min_samples_split': 130},\n",
       "  {'max_depth': 2, 'min_samples_split': 150},\n",
       "  {'max_depth': 2, 'min_samples_split': 170},\n",
       "  {'max_depth': 2, 'min_samples_split': 190},\n",
       "  {'max_depth': 2, 'min_samples_split': 210},\n",
       "  {'max_depth': 2, 'min_samples_split': 230},\n",
       "  {'max_depth': 2, 'min_samples_split': 250},\n",
       "  {'max_depth': 2, 'min_samples_split': 270},\n",
       "  {'max_depth': 2, 'min_samples_split': 290},\n",
       "  {'max_depth': 2, 'min_samples_split': 310},\n",
       "  {'max_depth': 2, 'min_samples_split': 330},\n",
       "  {'max_depth': 2, 'min_samples_split': 350},\n",
       "  {'max_depth': 2, 'min_samples_split': 370},\n",
       "  {'max_depth': 2, 'min_samples_split': 390},\n",
       "  {'max_depth': 2, 'min_samples_split': 410},\n",
       "  {'max_depth': 2, 'min_samples_split': 430},\n",
       "  {'max_depth': 2, 'min_samples_split': 450},\n",
       "  {'max_depth': 2, 'min_samples_split': 470},\n",
       "  {'max_depth': 2, 'min_samples_split': 490},\n",
       "  {'max_depth': 3, 'min_samples_split': 10},\n",
       "  {'max_depth': 3, 'min_samples_split': 30},\n",
       "  {'max_depth': 3, 'min_samples_split': 50},\n",
       "  {'max_depth': 3, 'min_samples_split': 70},\n",
       "  {'max_depth': 3, 'min_samples_split': 90},\n",
       "  {'max_depth': 3, 'min_samples_split': 110},\n",
       "  {'max_depth': 3, 'min_samples_split': 130},\n",
       "  {'max_depth': 3, 'min_samples_split': 150},\n",
       "  {'max_depth': 3, 'min_samples_split': 170},\n",
       "  {'max_depth': 3, 'min_samples_split': 190},\n",
       "  {'max_depth': 3, 'min_samples_split': 210},\n",
       "  {'max_depth': 3, 'min_samples_split': 230},\n",
       "  {'max_depth': 3, 'min_samples_split': 250},\n",
       "  {'max_depth': 3, 'min_samples_split': 270},\n",
       "  {'max_depth': 3, 'min_samples_split': 290},\n",
       "  {'max_depth': 3, 'min_samples_split': 310},\n",
       "  {'max_depth': 3, 'min_samples_split': 330},\n",
       "  {'max_depth': 3, 'min_samples_split': 350},\n",
       "  {'max_depth': 3, 'min_samples_split': 370},\n",
       "  {'max_depth': 3, 'min_samples_split': 390},\n",
       "  {'max_depth': 3, 'min_samples_split': 410},\n",
       "  {'max_depth': 3, 'min_samples_split': 430},\n",
       "  {'max_depth': 3, 'min_samples_split': 450},\n",
       "  {'max_depth': 3, 'min_samples_split': 470},\n",
       "  {'max_depth': 3, 'min_samples_split': 490},\n",
       "  {'max_depth': 4, 'min_samples_split': 10},\n",
       "  {'max_depth': 4, 'min_samples_split': 30},\n",
       "  {'max_depth': 4, 'min_samples_split': 50},\n",
       "  {'max_depth': 4, 'min_samples_split': 70},\n",
       "  {'max_depth': 4, 'min_samples_split': 90},\n",
       "  {'max_depth': 4, 'min_samples_split': 110},\n",
       "  {'max_depth': 4, 'min_samples_split': 130},\n",
       "  {'max_depth': 4, 'min_samples_split': 150},\n",
       "  {'max_depth': 4, 'min_samples_split': 170},\n",
       "  {'max_depth': 4, 'min_samples_split': 190},\n",
       "  {'max_depth': 4, 'min_samples_split': 210},\n",
       "  {'max_depth': 4, 'min_samples_split': 230},\n",
       "  {'max_depth': 4, 'min_samples_split': 250},\n",
       "  {'max_depth': 4, 'min_samples_split': 270},\n",
       "  {'max_depth': 4, 'min_samples_split': 290},\n",
       "  {'max_depth': 4, 'min_samples_split': 310},\n",
       "  {'max_depth': 4, 'min_samples_split': 330},\n",
       "  {'max_depth': 4, 'min_samples_split': 350},\n",
       "  {'max_depth': 4, 'min_samples_split': 370},\n",
       "  {'max_depth': 4, 'min_samples_split': 390},\n",
       "  {'max_depth': 4, 'min_samples_split': 410},\n",
       "  {'max_depth': 4, 'min_samples_split': 430},\n",
       "  {'max_depth': 4, 'min_samples_split': 450},\n",
       "  {'max_depth': 4, 'min_samples_split': 470},\n",
       "  {'max_depth': 4, 'min_samples_split': 490},\n",
       "  {'max_depth': 5, 'min_samples_split': 10},\n",
       "  {'max_depth': 5, 'min_samples_split': 30},\n",
       "  {'max_depth': 5, 'min_samples_split': 50},\n",
       "  {'max_depth': 5, 'min_samples_split': 70},\n",
       "  {'max_depth': 5, 'min_samples_split': 90},\n",
       "  {'max_depth': 5, 'min_samples_split': 110},\n",
       "  {'max_depth': 5, 'min_samples_split': 130},\n",
       "  {'max_depth': 5, 'min_samples_split': 150},\n",
       "  {'max_depth': 5, 'min_samples_split': 170},\n",
       "  {'max_depth': 5, 'min_samples_split': 190},\n",
       "  {'max_depth': 5, 'min_samples_split': 210},\n",
       "  {'max_depth': 5, 'min_samples_split': 230},\n",
       "  {'max_depth': 5, 'min_samples_split': 250},\n",
       "  {'max_depth': 5, 'min_samples_split': 270},\n",
       "  {'max_depth': 5, 'min_samples_split': 290},\n",
       "  {'max_depth': 5, 'min_samples_split': 310},\n",
       "  {'max_depth': 5, 'min_samples_split': 330},\n",
       "  {'max_depth': 5, 'min_samples_split': 350},\n",
       "  {'max_depth': 5, 'min_samples_split': 370},\n",
       "  {'max_depth': 5, 'min_samples_split': 390},\n",
       "  {'max_depth': 5, 'min_samples_split': 410},\n",
       "  {'max_depth': 5, 'min_samples_split': 430},\n",
       "  {'max_depth': 5, 'min_samples_split': 450},\n",
       "  {'max_depth': 5, 'min_samples_split': 470},\n",
       "  {'max_depth': 5, 'min_samples_split': 490},\n",
       "  {'max_depth': 6, 'min_samples_split': 10},\n",
       "  {'max_depth': 6, 'min_samples_split': 30},\n",
       "  {'max_depth': 6, 'min_samples_split': 50},\n",
       "  {'max_depth': 6, 'min_samples_split': 70},\n",
       "  {'max_depth': 6, 'min_samples_split': 90},\n",
       "  {'max_depth': 6, 'min_samples_split': 110},\n",
       "  {'max_depth': 6, 'min_samples_split': 130},\n",
       "  {'max_depth': 6, 'min_samples_split': 150},\n",
       "  {'max_depth': 6, 'min_samples_split': 170},\n",
       "  {'max_depth': 6, 'min_samples_split': 190},\n",
       "  {'max_depth': 6, 'min_samples_split': 210},\n",
       "  {'max_depth': 6, 'min_samples_split': 230},\n",
       "  {'max_depth': 6, 'min_samples_split': 250},\n",
       "  {'max_depth': 6, 'min_samples_split': 270},\n",
       "  {'max_depth': 6, 'min_samples_split': 290},\n",
       "  {'max_depth': 6, 'min_samples_split': 310},\n",
       "  {'max_depth': 6, 'min_samples_split': 330},\n",
       "  {'max_depth': 6, 'min_samples_split': 350},\n",
       "  {'max_depth': 6, 'min_samples_split': 370},\n",
       "  {'max_depth': 6, 'min_samples_split': 390},\n",
       "  {'max_depth': 6, 'min_samples_split': 410},\n",
       "  {'max_depth': 6, 'min_samples_split': 430},\n",
       "  {'max_depth': 6, 'min_samples_split': 450},\n",
       "  {'max_depth': 6, 'min_samples_split': 470},\n",
       "  {'max_depth': 6, 'min_samples_split': 490},\n",
       "  {'max_depth': 7, 'min_samples_split': 10},\n",
       "  {'max_depth': 7, 'min_samples_split': 30},\n",
       "  {'max_depth': 7, 'min_samples_split': 50},\n",
       "  {'max_depth': 7, 'min_samples_split': 70},\n",
       "  {'max_depth': 7, 'min_samples_split': 90},\n",
       "  {'max_depth': 7, 'min_samples_split': 110},\n",
       "  {'max_depth': 7, 'min_samples_split': 130},\n",
       "  {'max_depth': 7, 'min_samples_split': 150},\n",
       "  {'max_depth': 7, 'min_samples_split': 170},\n",
       "  {'max_depth': 7, 'min_samples_split': 190},\n",
       "  {'max_depth': 7, 'min_samples_split': 210},\n",
       "  {'max_depth': 7, 'min_samples_split': 230},\n",
       "  {'max_depth': 7, 'min_samples_split': 250},\n",
       "  {'max_depth': 7, 'min_samples_split': 270},\n",
       "  {'max_depth': 7, 'min_samples_split': 290},\n",
       "  {'max_depth': 7, 'min_samples_split': 310},\n",
       "  {'max_depth': 7, 'min_samples_split': 330},\n",
       "  {'max_depth': 7, 'min_samples_split': 350},\n",
       "  {'max_depth': 7, 'min_samples_split': 370},\n",
       "  {'max_depth': 7, 'min_samples_split': 390},\n",
       "  {'max_depth': 7, 'min_samples_split': 410},\n",
       "  {'max_depth': 7, 'min_samples_split': 430},\n",
       "  {'max_depth': 7, 'min_samples_split': 450},\n",
       "  {'max_depth': 7, 'min_samples_split': 470},\n",
       "  {'max_depth': 7, 'min_samples_split': 490},\n",
       "  {'max_depth': 8, 'min_samples_split': 10},\n",
       "  {'max_depth': 8, 'min_samples_split': 30},\n",
       "  {'max_depth': 8, 'min_samples_split': 50},\n",
       "  {'max_depth': 8, 'min_samples_split': 70},\n",
       "  {'max_depth': 8, 'min_samples_split': 90},\n",
       "  {'max_depth': 8, 'min_samples_split': 110},\n",
       "  {'max_depth': 8, 'min_samples_split': 130},\n",
       "  {'max_depth': 8, 'min_samples_split': 150},\n",
       "  {'max_depth': 8, 'min_samples_split': 170},\n",
       "  {'max_depth': 8, 'min_samples_split': 190},\n",
       "  {'max_depth': 8, 'min_samples_split': 210},\n",
       "  {'max_depth': 8, 'min_samples_split': 230},\n",
       "  {'max_depth': 8, 'min_samples_split': 250},\n",
       "  {'max_depth': 8, 'min_samples_split': 270},\n",
       "  {'max_depth': 8, 'min_samples_split': 290},\n",
       "  {'max_depth': 8, 'min_samples_split': 310},\n",
       "  {'max_depth': 8, 'min_samples_split': 330},\n",
       "  {'max_depth': 8, 'min_samples_split': 350},\n",
       "  {'max_depth': 8, 'min_samples_split': 370},\n",
       "  {'max_depth': 8, 'min_samples_split': 390},\n",
       "  {'max_depth': 8, 'min_samples_split': 410},\n",
       "  {'max_depth': 8, 'min_samples_split': 430},\n",
       "  {'max_depth': 8, 'min_samples_split': 450},\n",
       "  {'max_depth': 8, 'min_samples_split': 470},\n",
       "  {'max_depth': 8, 'min_samples_split': 490},\n",
       "  {'max_depth': 9, 'min_samples_split': 10},\n",
       "  {'max_depth': 9, 'min_samples_split': 30},\n",
       "  {'max_depth': 9, 'min_samples_split': 50},\n",
       "  {'max_depth': 9, 'min_samples_split': 70},\n",
       "  {'max_depth': 9, 'min_samples_split': 90},\n",
       "  {'max_depth': 9, 'min_samples_split': 110},\n",
       "  {'max_depth': 9, 'min_samples_split': 130},\n",
       "  {'max_depth': 9, 'min_samples_split': 150},\n",
       "  {'max_depth': 9, 'min_samples_split': 170},\n",
       "  {'max_depth': 9, 'min_samples_split': 190},\n",
       "  {'max_depth': 9, 'min_samples_split': 210},\n",
       "  {'max_depth': 9, 'min_samples_split': 230},\n",
       "  {'max_depth': 9, 'min_samples_split': 250},\n",
       "  {'max_depth': 9, 'min_samples_split': 270},\n",
       "  {'max_depth': 9, 'min_samples_split': 290},\n",
       "  {'max_depth': 9, 'min_samples_split': 310},\n",
       "  {'max_depth': 9, 'min_samples_split': 330},\n",
       "  {'max_depth': 9, 'min_samples_split': 350},\n",
       "  {'max_depth': 9, 'min_samples_split': 370},\n",
       "  {'max_depth': 9, 'min_samples_split': 390},\n",
       "  {'max_depth': 9, 'min_samples_split': 410},\n",
       "  {'max_depth': 9, 'min_samples_split': 430},\n",
       "  {'max_depth': 9, 'min_samples_split': 450},\n",
       "  {'max_depth': 9, 'min_samples_split': 470},\n",
       "  {'max_depth': 9, 'min_samples_split': 490},\n",
       "  {'max_depth': 10, 'min_samples_split': 10},\n",
       "  {'max_depth': 10, 'min_samples_split': 30},\n",
       "  {'max_depth': 10, 'min_samples_split': 50},\n",
       "  {'max_depth': 10, 'min_samples_split': 70},\n",
       "  {'max_depth': 10, 'min_samples_split': 90},\n",
       "  {'max_depth': 10, 'min_samples_split': 110},\n",
       "  {'max_depth': 10, 'min_samples_split': 130},\n",
       "  {'max_depth': 10, 'min_samples_split': 150},\n",
       "  {'max_depth': 10, 'min_samples_split': 170},\n",
       "  {'max_depth': 10, 'min_samples_split': 190},\n",
       "  {'max_depth': 10, 'min_samples_split': 210},\n",
       "  {'max_depth': 10, 'min_samples_split': 230},\n",
       "  {'max_depth': 10, 'min_samples_split': 250},\n",
       "  {'max_depth': 10, 'min_samples_split': 270},\n",
       "  {'max_depth': 10, 'min_samples_split': 290},\n",
       "  {'max_depth': 10, 'min_samples_split': 310},\n",
       "  {'max_depth': 10, 'min_samples_split': 330},\n",
       "  {'max_depth': 10, 'min_samples_split': 350},\n",
       "  {'max_depth': 10, 'min_samples_split': 370},\n",
       "  {'max_depth': 10, 'min_samples_split': 390},\n",
       "  {'max_depth': 10, 'min_samples_split': 410},\n",
       "  {'max_depth': 10, 'min_samples_split': 430},\n",
       "  {'max_depth': 10, 'min_samples_split': 450},\n",
       "  {'max_depth': 10, 'min_samples_split': 470},\n",
       "  {'max_depth': 10, 'min_samples_split': 490},\n",
       "  {'max_depth': 11, 'min_samples_split': 10},\n",
       "  {'max_depth': 11, 'min_samples_split': 30},\n",
       "  {'max_depth': 11, 'min_samples_split': 50},\n",
       "  {'max_depth': 11, 'min_samples_split': 70},\n",
       "  {'max_depth': 11, 'min_samples_split': 90},\n",
       "  {'max_depth': 11, 'min_samples_split': 110},\n",
       "  {'max_depth': 11, 'min_samples_split': 130},\n",
       "  {'max_depth': 11, 'min_samples_split': 150},\n",
       "  {'max_depth': 11, 'min_samples_split': 170},\n",
       "  {'max_depth': 11, 'min_samples_split': 190},\n",
       "  {'max_depth': 11, 'min_samples_split': 210},\n",
       "  {'max_depth': 11, 'min_samples_split': 230},\n",
       "  {'max_depth': 11, 'min_samples_split': 250},\n",
       "  {'max_depth': 11, 'min_samples_split': 270},\n",
       "  {'max_depth': 11, 'min_samples_split': 290},\n",
       "  {'max_depth': 11, 'min_samples_split': 310},\n",
       "  {'max_depth': 11, 'min_samples_split': 330},\n",
       "  {'max_depth': 11, 'min_samples_split': 350},\n",
       "  {'max_depth': 11, 'min_samples_split': 370},\n",
       "  {'max_depth': 11, 'min_samples_split': 390},\n",
       "  {'max_depth': 11, 'min_samples_split': 410},\n",
       "  {'max_depth': 11, 'min_samples_split': 430},\n",
       "  {'max_depth': 11, 'min_samples_split': 450},\n",
       "  {'max_depth': 11, 'min_samples_split': 470},\n",
       "  {'max_depth': 11, 'min_samples_split': 490},\n",
       "  {'max_depth': 12, 'min_samples_split': 10},\n",
       "  {'max_depth': 12, 'min_samples_split': 30},\n",
       "  {'max_depth': 12, 'min_samples_split': 50},\n",
       "  {'max_depth': 12, 'min_samples_split': 70},\n",
       "  {'max_depth': 12, 'min_samples_split': 90},\n",
       "  {'max_depth': 12, 'min_samples_split': 110},\n",
       "  {'max_depth': 12, 'min_samples_split': 130},\n",
       "  {'max_depth': 12, 'min_samples_split': 150},\n",
       "  {'max_depth': 12, 'min_samples_split': 170},\n",
       "  {'max_depth': 12, 'min_samples_split': 190},\n",
       "  {'max_depth': 12, 'min_samples_split': 210},\n",
       "  {'max_depth': 12, 'min_samples_split': 230},\n",
       "  {'max_depth': 12, 'min_samples_split': 250},\n",
       "  {'max_depth': 12, 'min_samples_split': 270},\n",
       "  {'max_depth': 12, 'min_samples_split': 290},\n",
       "  {'max_depth': 12, 'min_samples_split': 310},\n",
       "  {'max_depth': 12, 'min_samples_split': 330},\n",
       "  {'max_depth': 12, 'min_samples_split': 350},\n",
       "  {'max_depth': 12, 'min_samples_split': 370},\n",
       "  {'max_depth': 12, 'min_samples_split': 390},\n",
       "  {'max_depth': 12, 'min_samples_split': 410},\n",
       "  {'max_depth': 12, 'min_samples_split': 430},\n",
       "  {'max_depth': 12, 'min_samples_split': 450},\n",
       "  {'max_depth': 12, 'min_samples_split': 470},\n",
       "  {'max_depth': 12, 'min_samples_split': 490},\n",
       "  {'max_depth': 13, 'min_samples_split': 10},\n",
       "  {'max_depth': 13, 'min_samples_split': 30},\n",
       "  {'max_depth': 13, 'min_samples_split': 50},\n",
       "  {'max_depth': 13, 'min_samples_split': 70},\n",
       "  {'max_depth': 13, 'min_samples_split': 90},\n",
       "  {'max_depth': 13, 'min_samples_split': 110},\n",
       "  {'max_depth': 13, 'min_samples_split': 130},\n",
       "  {'max_depth': 13, 'min_samples_split': 150},\n",
       "  {'max_depth': 13, 'min_samples_split': 170},\n",
       "  {'max_depth': 13, 'min_samples_split': 190},\n",
       "  {'max_depth': 13, 'min_samples_split': 210},\n",
       "  {'max_depth': 13, 'min_samples_split': 230},\n",
       "  {'max_depth': 13, 'min_samples_split': 250},\n",
       "  {'max_depth': 13, 'min_samples_split': 270},\n",
       "  {'max_depth': 13, 'min_samples_split': 290},\n",
       "  {'max_depth': 13, 'min_samples_split': 310},\n",
       "  {'max_depth': 13, 'min_samples_split': 330},\n",
       "  {'max_depth': 13, 'min_samples_split': 350},\n",
       "  {'max_depth': 13, 'min_samples_split': 370},\n",
       "  {'max_depth': 13, 'min_samples_split': 390},\n",
       "  {'max_depth': 13, 'min_samples_split': 410},\n",
       "  {'max_depth': 13, 'min_samples_split': 430},\n",
       "  {'max_depth': 13, 'min_samples_split': 450},\n",
       "  {'max_depth': 13, 'min_samples_split': 470},\n",
       "  {'max_depth': 13, 'min_samples_split': 490},\n",
       "  {'max_depth': 14, 'min_samples_split': 10},\n",
       "  {'max_depth': 14, 'min_samples_split': 30},\n",
       "  {'max_depth': 14, 'min_samples_split': 50},\n",
       "  {'max_depth': 14, 'min_samples_split': 70},\n",
       "  {'max_depth': 14, 'min_samples_split': 90},\n",
       "  {'max_depth': 14, 'min_samples_split': 110},\n",
       "  {'max_depth': 14, 'min_samples_split': 130},\n",
       "  {'max_depth': 14, 'min_samples_split': 150},\n",
       "  {'max_depth': 14, 'min_samples_split': 170},\n",
       "  {'max_depth': 14, 'min_samples_split': 190},\n",
       "  {'max_depth': 14, 'min_samples_split': 210},\n",
       "  {'max_depth': 14, 'min_samples_split': 230},\n",
       "  {'max_depth': 14, 'min_samples_split': 250},\n",
       "  {'max_depth': 14, 'min_samples_split': 270},\n",
       "  {'max_depth': 14, 'min_samples_split': 290},\n",
       "  {'max_depth': 14, 'min_samples_split': 310},\n",
       "  {'max_depth': 14, 'min_samples_split': 330},\n",
       "  {'max_depth': 14, 'min_samples_split': 350},\n",
       "  {'max_depth': 14, 'min_samples_split': 370},\n",
       "  {'max_depth': 14, 'min_samples_split': 390},\n",
       "  {'max_depth': 14, 'min_samples_split': 410},\n",
       "  {'max_depth': 14, 'min_samples_split': 430},\n",
       "  {'max_depth': 14, 'min_samples_split': 450},\n",
       "  {'max_depth': 14, 'min_samples_split': 470},\n",
       "  {'max_depth': 14, 'min_samples_split': 490},\n",
       "  {'max_depth': 15, 'min_samples_split': 10},\n",
       "  {'max_depth': 15, 'min_samples_split': 30},\n",
       "  {'max_depth': 15, 'min_samples_split': 50},\n",
       "  {'max_depth': 15, 'min_samples_split': 70},\n",
       "  {'max_depth': 15, 'min_samples_split': 90},\n",
       "  {'max_depth': 15, 'min_samples_split': 110},\n",
       "  {'max_depth': 15, 'min_samples_split': 130},\n",
       "  {'max_depth': 15, 'min_samples_split': 150},\n",
       "  {'max_depth': 15, 'min_samples_split': 170},\n",
       "  {'max_depth': 15, 'min_samples_split': 190},\n",
       "  {'max_depth': 15, 'min_samples_split': 210},\n",
       "  {'max_depth': 15, 'min_samples_split': 230},\n",
       "  {'max_depth': 15, 'min_samples_split': 250},\n",
       "  {'max_depth': 15, 'min_samples_split': 270},\n",
       "  {'max_depth': 15, 'min_samples_split': 290},\n",
       "  {'max_depth': 15, 'min_samples_split': 310},\n",
       "  {'max_depth': 15, 'min_samples_split': 330},\n",
       "  {'max_depth': 15, 'min_samples_split': 350},\n",
       "  {'max_depth': 15, 'min_samples_split': 370},\n",
       "  {'max_depth': 15, 'min_samples_split': 390},\n",
       "  {'max_depth': 15, 'min_samples_split': 410},\n",
       "  {'max_depth': 15, 'min_samples_split': 430},\n",
       "  {'max_depth': 15, 'min_samples_split': 450},\n",
       "  {'max_depth': 15, 'min_samples_split': 470},\n",
       "  {'max_depth': 15, 'min_samples_split': 490},\n",
       "  {'max_depth': 16, 'min_samples_split': 10},\n",
       "  {'max_depth': 16, 'min_samples_split': 30},\n",
       "  {'max_depth': 16, 'min_samples_split': 50},\n",
       "  {'max_depth': 16, 'min_samples_split': 70},\n",
       "  {'max_depth': 16, 'min_samples_split': 90},\n",
       "  {'max_depth': 16, 'min_samples_split': 110},\n",
       "  {'max_depth': 16, 'min_samples_split': 130},\n",
       "  {'max_depth': 16, 'min_samples_split': 150},\n",
       "  {'max_depth': 16, 'min_samples_split': 170},\n",
       "  {'max_depth': 16, 'min_samples_split': 190},\n",
       "  {'max_depth': 16, 'min_samples_split': 210},\n",
       "  {'max_depth': 16, 'min_samples_split': 230},\n",
       "  {'max_depth': 16, 'min_samples_split': 250},\n",
       "  {'max_depth': 16, 'min_samples_split': 270},\n",
       "  {'max_depth': 16, 'min_samples_split': 290},\n",
       "  {'max_depth': 16, 'min_samples_split': 310},\n",
       "  {'max_depth': 16, 'min_samples_split': 330},\n",
       "  {'max_depth': 16, 'min_samples_split': 350},\n",
       "  {'max_depth': 16, 'min_samples_split': 370},\n",
       "  {'max_depth': 16, 'min_samples_split': 390},\n",
       "  {'max_depth': 16, 'min_samples_split': 410},\n",
       "  {'max_depth': 16, 'min_samples_split': 430},\n",
       "  {'max_depth': 16, 'min_samples_split': 450},\n",
       "  {'max_depth': 16, 'min_samples_split': 470},\n",
       "  {'max_depth': 16, 'min_samples_split': 490},\n",
       "  {'max_depth': 17, 'min_samples_split': 10},\n",
       "  {'max_depth': 17, 'min_samples_split': 30},\n",
       "  {'max_depth': 17, 'min_samples_split': 50},\n",
       "  {'max_depth': 17, 'min_samples_split': 70},\n",
       "  {'max_depth': 17, 'min_samples_split': 90},\n",
       "  {'max_depth': 17, 'min_samples_split': 110},\n",
       "  {'max_depth': 17, 'min_samples_split': 130},\n",
       "  {'max_depth': 17, 'min_samples_split': 150},\n",
       "  {'max_depth': 17, 'min_samples_split': 170},\n",
       "  {'max_depth': 17, 'min_samples_split': 190},\n",
       "  {'max_depth': 17, 'min_samples_split': 210},\n",
       "  {'max_depth': 17, 'min_samples_split': 230},\n",
       "  {'max_depth': 17, 'min_samples_split': 250},\n",
       "  {'max_depth': 17, 'min_samples_split': 270},\n",
       "  {'max_depth': 17, 'min_samples_split': 290},\n",
       "  {'max_depth': 17, 'min_samples_split': 310},\n",
       "  {'max_depth': 17, 'min_samples_split': 330},\n",
       "  {'max_depth': 17, 'min_samples_split': 350},\n",
       "  {'max_depth': 17, 'min_samples_split': 370},\n",
       "  {'max_depth': 17, 'min_samples_split': 390},\n",
       "  {'max_depth': 17, 'min_samples_split': 410},\n",
       "  {'max_depth': 17, 'min_samples_split': 430},\n",
       "  {'max_depth': 17, 'min_samples_split': 450},\n",
       "  {'max_depth': 17, 'min_samples_split': 470},\n",
       "  {'max_depth': 17, 'min_samples_split': 490}],\n",
       " 'split0_test_score': array([0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.80291971, 0.80291971, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.80291971, 0.80291971, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.73722628, 0.74452555, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.72992701, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.73722628, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.73722628, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.72262774, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.69343066, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.69343066, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.69343066, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.69343066, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.69343066, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.69343066, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.69343066, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.69343066, 0.73722628, 0.76642336, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.81751825,\n",
       "        0.81751825, 0.81751825, 0.81751825, 0.81751825, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ]),\n",
       " 'split1_test_score': array([0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.78832117, 0.78832117, 0.78832117, 0.78832117, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.78832117, 0.78832117, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.78832117, 0.78832117, 0.78832117, 0.78832117, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.78832117, 0.78832117, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.72262774, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.75912409, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.75182482, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.74452555, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.72262774, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.72262774, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.70072993, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.70072993, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.70072993, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.70072993, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.70072993, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.70072993, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.70072993, 0.72262774, 0.76642336, 0.76642336, 0.76642336,\n",
       "        0.76642336, 0.76642336, 0.76642336, 0.76642336, 0.78832117,\n",
       "        0.78832117, 0.78832117, 0.80291971, 0.80291971, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ]),\n",
       " 'split2_test_score': array([0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.83211679, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.83211679, 0.82481752, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.83941606, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.76642336, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.77372263, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.76642336, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.76642336, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.75912409, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.75182482, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.75182482, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.74452555, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.74452555, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.74452555, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.74452555, 0.83211679, 0.83211679, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.82481752,\n",
       "        0.82481752, 0.82481752, 0.82481752, 0.82481752, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ]),\n",
       " 'mean_test_score': array([0.81508516, 0.81508516, 0.81508516, 0.81508516, 0.81508516,\n",
       "        0.81508516, 0.81508516, 0.81508516, 0.81508516, 0.81508516,\n",
       "        0.81508516, 0.81508516, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.8053528 , 0.8053528 , 0.81021898, 0.81021898, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81021898, 0.81021898, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.8053528 , 0.8053528 , 0.81021898, 0.81021898, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81021898, 0.81021898, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.77858881, 0.77858881, 0.78588808, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.76155718, 0.76155718, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.77858881, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.75182482, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.74695864, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7323601 , 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.72749392, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.71776156, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.71532847, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.71532847, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.71289538, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.71289538, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.71289538, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.71289538, 0.76399027, 0.78832117, 0.80291971, 0.80291971,\n",
       "        0.80291971, 0.80291971, 0.80291971, 0.80291971, 0.81021898,\n",
       "        0.81021898, 0.81021898, 0.81508516, 0.81508516, 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ,\n",
       "        0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 , 0.7080292 ]),\n",
       " 'std_test_score': array([0.00910379, 0.00910379, 0.00910379, 0.00910379, 0.00910379,\n",
       "        0.00910379, 0.00910379, 0.00910379, 0.00910379, 0.00910379,\n",
       "        0.00910379, 0.00910379, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01499857, 0.01499857, 0.01576823, 0.01576823, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.01576823, 0.01576823, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01499857, 0.01499857, 0.01576823, 0.01576823, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.01576823, 0.01576823, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0396825 , 0.03388902, 0.02752727, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04998209, 0.0451271 , 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04393058, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01191966, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02093023, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02481275, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02999715, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02939914, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02597829, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02597829, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02256355, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02256355, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02256355, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02256355, 0.04853999, 0.03096818, 0.02597829, 0.02597829,\n",
       "        0.02597829, 0.02597829, 0.02597829, 0.02597829, 0.01576823,\n",
       "        0.01576823, 0.01576823, 0.00910379, 0.00910379, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_score': array([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 109,\n",
       "        109,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,   1,   1,\n",
       "        239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 109, 109,\n",
       "         47,  47,  47,  47,  47,  47,  47,  47,  47,  47,   1,   1, 239,\n",
       "        239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 211, 211, 210,\n",
       "        113, 113, 113, 113, 113, 113,  47,  47,  47,   1,   1, 239, 239,\n",
       "        239, 239, 239, 239, 239, 239, 239, 239, 239, 226, 226, 197, 113,\n",
       "        113, 113, 113, 113, 113,  47,  47,  47,   1,   1, 239, 239, 239,\n",
       "        239, 239, 239, 239, 239, 239, 239, 239, 211, 214, 197, 113, 113,\n",
       "        113, 113, 113, 113,  47,  47,  47,   1,   1, 239, 239, 239, 239,\n",
       "        239, 239, 239, 239, 239, 239, 239, 228, 214, 197, 113, 113, 113,\n",
       "        113, 113, 113,  47,  47,  47,   1,   1, 239, 239, 239, 239, 239,\n",
       "        239, 239, 239, 239, 239, 239, 229, 214, 197, 113, 113, 113, 113,\n",
       "        113, 113,  47,  47,  47,   1,   1, 239, 239, 239, 239, 239, 239,\n",
       "        239, 239, 239, 239, 239, 230, 214, 197, 113, 113, 113, 113, 113,\n",
       "        113,  47,  47,  47,   1,   1, 239, 239, 239, 239, 239, 239, 239,\n",
       "        239, 239, 239, 239, 231, 214, 197, 113, 113, 113, 113, 113, 113,\n",
       "         47,  47,  47,   1,   1, 239, 239, 239, 239, 239, 239, 239, 239,\n",
       "        239, 239, 239, 232, 214, 197, 113, 113, 113, 113, 113, 113,  47,\n",
       "         47,  47,   1,   1, 239, 239, 239, 239, 239, 239, 239, 239, 239,\n",
       "        239, 239, 233, 214, 197, 113, 113, 113, 113, 113, 113,  47,  47,\n",
       "         47,   1,   1, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239,\n",
       "        239, 233, 214, 197, 113, 113, 113, 113, 113, 113,  47,  47,  47,\n",
       "          1,   1, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239,\n",
       "        235, 214, 197, 113, 113, 113, 113, 113, 113,  47,  47,  47,   1,\n",
       "          1, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 235,\n",
       "        214, 197, 113, 113, 113, 113, 113, 113,  47,  47,  47,   1,   1,\n",
       "        239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 235, 214,\n",
       "        197, 113, 113, 113, 113, 113, 113,  47,  47,  47,   1,   1, 239,\n",
       "        239, 239, 239, 239, 239, 239, 239, 239, 239, 239, 235, 214, 197,\n",
       "        113, 113, 113, 113, 113, 113,  47,  47,  47,   1,   1, 239, 239,\n",
       "        239, 239, 239, 239, 239, 239, 239, 239, 239])}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc is  0.8150851581508516\n",
      "test acc is  0.7980295566502463\n"
     ]
    }
   ],
   "source": [
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "# print(clf)\n",
    "# clf=clf.fit(x_train,np.squeeze(y_train.values))\n",
    "# print(clf.feature_importances_,end='\\n\\n\\n')\n",
    "train_preds=clf.predict(x_train)\n",
    "train_acc=accuracy_score(y_train, train_preds)\n",
    "print('train acc is ',train_acc)\n",
    "\n",
    "\n",
    "test_preds=clf.predict(x_test)\n",
    "test_acc=accuracy_score(y_test,test_preds)\n",
    "print('test acc is ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('dt.txt',train_preds,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is it a joke or what we have same thing with LR and SVMs .If we go with min_samples_split=2 and max_depth =1  than train accuracy is 1 and test acc=71 %**\n",
    "\n",
    "\n",
    "**let us see the most important features, and exculde all the non relevant features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt=clf.best_estimator_\n",
    "best_dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames=['Gender','Married','Dependents', 'Education',\n",
    " 'Self_Employed', 'ApplicantIncome',\n",
    " 'CoapplicantIncome', 'LoanAmount',\n",
    " 'Loan_Amount_Term', 'Credit_History',\n",
    " 'Property_Area',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 163.07999999999998, 'Credit_History <= 0.421\\nentropy = 0.413\\nsamples = 411\\nvalue = [120, 291]\\nclass = Yes'),\n",
       " Text(83.7, 54.360000000000014, 'entropy = 0.168\\nsamples = 54\\nvalue = [49, 5]\\nclass = NO'),\n",
       " Text(251.10000000000002, 54.360000000000014, 'entropy = 0.319\\nsamples = 357\\nvalue = [71, 286]\\nclass = Yes')]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(best_dt,feature_names=fnames,class_names=['NO','Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit History seems promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Work let us use Ensembling\n",
    "\n",
    "\n",
    "If Ensembles also cannot Work Then use NN\n",
    "\n",
    "##### Try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try Boosting \n",
    "###### Try XG Boost Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm goes by lots of different names such as gradient boosting, multiple additive regression trees, stochastic gradient boosting or gradient boosting machines.\n",
    "\n",
    "Boosting is an ensemble technique where new models are added to correct the errors made by existing models. Models are added sequentially until no further improvements can be made. A popular example is the AdaBoost algorithm that weights data points that are hard to predict.\n",
    "\n",
    "Gradient boosting is an approach where new models are created that predict the residuals or errors of prior models and then added together to make the final prediction. It is called gradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new models.\n",
    "\n",
    "This approach supports both regression and classification predictive modeling problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "train acc is  0.8710462287104623\n",
      "test acc is  0.7980295566502463\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, np.squeeze(y_train.values))\n",
    "print(model)\n",
    "\n",
    "train_preds = model.predict(x_train)\n",
    "train_preds = [round(value) for value in train_preds]\n",
    "# model predict probs from 0 to 1 and thus we round them to app value\n",
    "train_acc=accuracy_score(y_train, train_preds)\n",
    "print('train acc is ',train_acc)\n",
    "\n",
    "\n",
    "test_preds=model.predict(x_test)\n",
    "test_acc=accuracy_score(y_test,test_preds)\n",
    "print('test acc is ',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Acc shot up, let us tune this https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us Use NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
